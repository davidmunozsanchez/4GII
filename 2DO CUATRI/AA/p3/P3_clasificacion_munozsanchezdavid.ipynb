{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Aprendizaje Automático - Práctica 3 - Ajuste de Modelos Lineales\n",
        "\n",
        "# Problema de Clasificación\n",
        "\n",
        "#### Valoración máxima: 6 puntos \n",
        "\n",
        "#### Fecha límite de entrega: 4 de Junio de 2023 a las 23:59\n",
        "\n",
        "#### Entrega a través de https://pradogrado2223.ugr.es/\n",
        "\n",
        "### Nombre completo: <mark>DAVID MUÑOZ SÁNCHEZ</mark>\n",
        "\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "VvcaSf5uskbO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Normas de desarrollo y entrega de trabajos**\n",
        "\n",
        "- Única y exclusivamente se debe entregar este Notebook de Colab (fichero .ipynb). No es necesario entregar ninguna memoria externa, pero el código debe estar bien comentado, y todas las decisiones tomadas y el trabajo desarrollado deben documentarse suficientemente en celdas de texto. \n",
        "\n",
        "- La entrega en PRADO está configurada para permitir sucesivas entregas de la práctica. Desde este punto de vista, se recomienda subir versiones de la práctica a medida que se van realizando los distintos ejercicios propuestos, y no dejarlo todo para el final, dado que es altamente improbable que se extienda la fecha de entrega.  \n",
        "\n",
        "- Reiterar que es obligatorio documentar las valoraciones y decisiones adoptadas en el desarrollo de cada uno de los apartados. Debe incluirse también una valoración razonada sobre la calidad de los\n",
        "resultados obtenidos. Sin esta documentación, se considera que el trabajo NO ha sido presentado. \n",
        "\n",
        "- Se debe respetar la estructura y secciones del Notebook. Esto servirá para agilizar las correcciones, así como para identificar con facilidad qué ejercicio/apartado se está respondiendo. \n",
        "\n",
        "- El codigo NO puede escribir nada a disco.\n",
        "\n",
        "- Se espera que el código siempre lea de un directorio llamado 'drive/MyDrive/Colab Notebooks/datos/', situado dentro del directorio donde se desarrolla y ejecuta la práctica. No se admiten excepciones a esta ruta de acceso a los datos. \n",
        "\n",
        "- Una entrega es apta para ser corregida si se puede ejecutar de principio a fin sin errores.\n",
        "\n",
        "- No es válido usar opciones en las entradas (es decir, utilizar el comando `input`, por ejemplo, para que el usuario escoja el valor de las variables para ejecutar el programa). Para ello, se deben fijar al comienzo los valores\n",
        "por defecto que se consideren óptimos o que se soliciten en el enunciado.\n",
        "\n",
        "- El código debe estar obligatoriamente comentado explicando lo que realizan los distintos apartados y/o bloques.\n",
        "\n",
        "- Se entrega solamente este Notebook, y no los datos empleados.\n",
        "\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "rqJiCKQ2s84e"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "<font color='blue'>Este trabajo  se centra en el ajuste y selección del mejor predictor lineal para un conjunto de datos dado. Para ello, se recomienda el uso de la librería Scikit-Learn (https://scikit-learn.org/). Esta librería contiene funciones de alto nivel que pueden ser muy útiles para el desarrollo de la práctica. En cualquier caso, para cada función de Scikit-Learn que se use, debe explicar por qué es necesario su uso, así como explicar su funcionamiento y el significado de todos sus parámetros. En relación con este punto, los valores por defecto en la librería no se consideran elecciones justificadas $\\textit{a priori}$ y, al igual que en el resto de la práctica, decisiones sin justificación y resultados sin interpretación no serán considerados válidos. \n",
        "\n"
      ],
      "metadata": {
        "id": "oVNyPZGSwKCF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero a tener en cuenta: se nos da el DataSet en varias partes. Por así decirlo, hay uno completo, y otro para el cuál las etiquetas vienen separadas. Estos dos últimos se uniran por columnas y el conjunto resultante se unirá por filas al primero."
      ],
      "metadata": {
        "id": "_Qzio5CyfAmX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "etiq_data2 = pd.read_csv(\"drive/MyDrive/Colab Notebooks/datos/tictgts2000.txt\", sep=' ', low_memory=False, header=None)\n",
        "data2 = pd.read_csv(\"drive/MyDrive/Colab Notebooks/datos/ticeval2000.txt\", sep='\\t', low_memory=False, header=None)\n",
        "data1 = pd.read_csv(\"drive/MyDrive/Colab Notebooks/datos/ticdata2000.txt\", sep='\\t', low_memory=False, header=None)\n",
        "\n",
        "etiq_data2[85] = etiq_data2[0]\n",
        "del etiq_data2[0]\n",
        "\n",
        "resultado1 = pd.concat([data2, etiq_data2], axis=1)\n",
        "\n",
        "resultado = pd.concat([data1,resultado1],axis=0)\n",
        "\n",
        "resultado\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 505
        },
        "id": "euPEH-FVfOuE",
        "outputId": "1474555f-28ae-4a8e-df28-9a1cee63ae33"
      },
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      0   1   2   3   4   5   6   7   8   9   ...  76  77  78  79  80  81  82  \\\n",
              "0     33   1   3   2   8   0   5   1   3   7  ...   0   0   0   1   0   0   0   \n",
              "1     37   1   2   2   8   1   4   1   4   6  ...   0   0   0   1   0   0   0   \n",
              "2     37   1   2   2   8   0   4   2   4   3  ...   0   0   0   1   0   0   0   \n",
              "3      9   1   3   3   3   2   3   2   4   5  ...   0   0   0   1   0   0   0   \n",
              "4     40   1   4   2  10   1   4   1   4   7  ...   0   0   0   1   0   0   0   \n",
              "...   ..  ..  ..  ..  ..  ..  ..  ..  ..  ..  ...  ..  ..  ..  ..  ..  ..  ..   \n",
              "3995  33   1   2   4   8   0   7   2   0   5  ...   0   0   0   1   0   0   0   \n",
              "3996  24   1   2   3   5   1   5   1   3   4  ...   0   0   0   1   0   0   0   \n",
              "3997  36   1   2   3   8   1   5   1   3   7  ...   0   0   0   1   0   0   0   \n",
              "3998  33   1   3   3   8   1   4   2   3   7  ...   0   0   0   0   0   0   0   \n",
              "3999   8   1   2   3   2   4   3   0   3   5  ...   0   0   0   1   0   0   0   \n",
              "\n",
              "      83  84  85  \n",
              "0      0   0   0  \n",
              "1      0   0   0  \n",
              "2      0   0   0  \n",
              "3      0   0   0  \n",
              "4      0   0   0  \n",
              "...   ..  ..  ..  \n",
              "3995   0   0   0  \n",
              "3996   0   0   1  \n",
              "3997   1   0   0  \n",
              "3998   0   0   0  \n",
              "3999   0   0   0  \n",
              "\n",
              "[9822 rows x 86 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd502e1b-8632-4f7a-bdf5-2aac86154aa9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "      <th>85</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>37</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>40</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>10</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3995</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3996</th>\n",
              "      <td>24</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3997</th>\n",
              "      <td>36</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3998</th>\n",
              "      <td>33</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3999</th>\n",
              "      <td>8</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>9822 rows × 86 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd502e1b-8632-4f7a-bdf5-2aac86154aa9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd502e1b-8632-4f7a-bdf5-2aac86154aa9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd502e1b-8632-4f7a-bdf5-2aac86154aa9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#ahora hay que ver valores faltantes\n",
        "\n",
        "print(resultado.to_numpy().dtype)\n",
        "\n",
        "def verificar_nan(dataset):\n",
        "    if dataset.isnull().values.any():\n",
        "        print(\"El dataset contiene valores NaN\")\n",
        "    else:\n",
        "        print(\"El dataset no contiene valores NaN\")\n",
        "def verificar_inf(dataset):\n",
        "    if dataset.isin([float('inf'), float('-inf')]).any().any():\n",
        "        print(\"El dataset contiene valores infinitos\")\n",
        "    else:\n",
        "        print(\"El dataset no contiene valores infinitos\")\n",
        "verificar_inf(resultado)\n",
        "verificar_nan(resultado)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8nCi2LmAkdE4",
        "outputId": "7d984b58-0889-4c34-f9ef-fc0f4b76ffce"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "int64\n",
            "El dataset no contiene valores infinitos\n",
            "El dataset no contiene valores NaN\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todas son numéricas en el sentido del formato y se puede asegurar que no hay ningún valor faltante, porque lo dice la documentación, y por la prueba del tipo que se acaba de hacer.\n",
        "\n",
        "A continuación, se indica, una a una, que significa cada columna del dataset, con objeto de transformarlas si son categóricas usando alguna técnica acorde a la información que muestren.\n"
      ],
      "metadata": {
        "id": "pN9MQfeT0Ak0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "DATA DICTIONARY\n",
        "\n",
        "Nr Name Description Domain\n",
        "+ 1 MOSTYPE Customer Subtype see **L0**\n",
        "+ 2 MAANTHUI Number of houses 1 – 10 \n",
        "+ 3 MGEMOMV Avg size household 1 – 6 \n",
        "+ 4 MGEMLEEF Avg age see **L1**\n",
        "+ 5 MOSHOOFD Customer main type see **L2**\n",
        "+ 6 MGODRK Roman catholic see **L3**\n",
        "+ 7 MGODPR Protestant ... \n",
        "+ 8 MGODOV Other religion \n",
        "+ 9 MGODGE No religion \n",
        "+ 10 MRELGE Married \n",
        "+ 11 MRELSA Living together \n",
        "+ 12 MRELOV Other relation \n",
        "+ 13 MFALLEEN Singles\n",
        "+ 14 MFGEKIND Household without children \n",
        "+ 15 MFWEKIND Household with children \n",
        "+ 16 MOPLHOOG High level education \n",
        "+ 17 MOPLMIDD Medium level education \n",
        "+ 18 MOPLLAAG Lower level education \n",
        "+ 19 MBERHOOG High status \n",
        "+ 20 MBERZELF Entrepreneur \n",
        "+ 21 MBERBOER Farmer \n",
        "+ 22 MBERMIDD Middle management \n",
        "+ 23 MBERARBG Skilled labourers \n",
        "+ 24 MBERARBO Unskilled labourers \n",
        "+ 25 MSKA Social class A \n",
        "+ 26 MSKB1 Social class B1 \n",
        "+ 27 MSKB2 Social class B2 \n",
        "+ 28 MSKC Social class C\n",
        "+ 29 MSKD Social class D\n",
        "+ 30 MHHUUR Rented house\n",
        "+ 31 MHKOOP Home owners \n",
        "+ 32 MAUT1 1 car \n",
        "+ 33 MAUT2 2 cars \n",
        "+ 34 MAUT0 No car \n",
        "+ 35 MZFONDS National Health Service \n",
        "+ 36 MZPART Private health insurance \n",
        "+ 37 MINKM30 Income < 30.000 \n",
        "+ 38 MINK3045 Income 30-45.000\n",
        "+ 39 MINK4575 Income 45-75.000 \n",
        "+ 40 MINK7512 Income 75-122.000 \n",
        "+ 41 MINK123M Income >123.000 \n",
        "+ 42 MINKGEM Average income \n",
        "+ 43 MKOOPKLA Purchasing power class\n",
        "+ 44 PWAPART Contribution private third party insurance see L4\n",
        "+ 45 PWABEDR Contribution third party insurance (firms) ... \n",
        "+ 46 PWALAND Contribution third party insurane (agriculture) \n",
        "+ 47 PPERSAUT Contribution car policies \n",
        "+ 48 PBESAUT Contribution delivery van policies \n",
        "+ 49 PMOTSCO Contribution motorcycle/scooter policies \n",
        "+ 50 PVRAAUT Contribution lorry policies \n",
        "+ 51 PAANHANG Contribution trailer policies \n",
        "+ 52 PTRACTOR Contribution tractor policies \n",
        "+ 53 PWERKT Contribution agricultural machines policies \n",
        "+ 54 PBROM Contribution moped policies \n",
        "+ 55 PLEVEN Contribution life insurances \n",
        "+ 56 PPERSONG Contribution private accident insurance policies \n",
        "+ 57 PGEZONG Contribution family accidents insurance policies \n",
        "+ 58 PWAOREG Contribution disability insurance policies \n",
        "+ 59 PBRAND Contribution fire policies\n",
        "+ 60 PZEILPL Contribution surfboard policies \n",
        "+ 61 PPLEZIER Contribution boat policies\n",
        "+ 62 PFIETS Contribution bicycle policies \n",
        "+ 63 PINBOED Contribution property insurance policies \n",
        "+ 64 PBYSTAND Contribution social security insurance policies \n",
        "+ 65 AWAPART Number of private third party insurance 1 - 12 \n",
        "+ 66 AWABEDR Number of third party insurance (firms) ... \n",
        "+ 67 AWALAND Number of third party insurane (agriculture) \n",
        "+ 68 APERSAUT Number of car policies \n",
        "+ 69 ABESAUT Number of delivery van policies \n",
        "+ 70 AMOTSCO Number of motorcycle/scooter policies \n",
        "+ 71 AVRAAUT Number of lorry policies \n",
        "+ 72 AAANHANG Number of trailer policies \n",
        "+ 73 ATRACTOR Number of tractor policies \n",
        "+ 74 AWERKT Number of agricultural machines policies \n",
        "+ 75 ABROM Number of moped policies \n",
        "+ 76 ALEVEN Number of life insurances \n",
        "+ 77 APERSONG Number of private accident insurance policies \n",
        "+ 78 AGEZONG Number of family accidents insurance policies\n",
        "+ 79 AWAOREG Number of disability insurance policies \n",
        "+ 80 ABRAND Number of fire policies \n",
        "+ 81 AZEILPL Number of surfboard policies \n",
        "+ 82 APLEZIER Number of boat policies \n",
        "+ 83 AFIETS Number of bicycle policies \n",
        "+ 84 AINBOED Number of property insurance policies \n",
        "+ 85 ABYSTAND Number of social security insurance policies\n",
        "+ 86 CARAVAN Number of mobile home policies 0 - 1 \n",
        "\n",
        "L0:\n",
        "\n",
        "Value Label\n",
        "+ 1 High Income, expensive child\n",
        "+ 2 Very Important Provincials\n",
        "+ 3 High status seniors\n",
        "+ 4 Affluent senior apartments\n",
        "+ 5 Mixed seniors\n",
        "+ 6 Career and childcare\n",
        "+ 7 Dinki's (double income no kids)\n",
        "+ 8 Middle class families\n",
        "+ 9 Modern, complete families\n",
        "+ 10 Stable family\n",
        "+ 11 Family starters\n",
        "+ 12 Affluent young families\n",
        "+ 13 Young all american family\n",
        "+ 14 Junior cosmopolitan\n",
        "+ 15 Senior cosmopolitans\n",
        "+ 16 Students in apartments\n",
        "+ 17 Fresh masters in the city\n",
        "+ 18 Single youth\n",
        "+ 19 Suburban youth\n",
        "+ 20 Etnically diverse\n",
        "+ 21 Young urban have-nots\n",
        "+ 22 Mixed apartment dwellers\n",
        "+ 23 Young and rising\n",
        "+ 24 Young, low educated \n",
        "+ 25 Young seniors in the city\n",
        "+ 26 Own home elderly\n",
        "+ 27 Seniors in apartments\n",
        "+ 28 Residential elderly\n",
        "+ 29 Porchless seniors: no front yard\n",
        "+ 30 Religious elderly singles\n",
        "+ 31 Low income catholics\n",
        "+ 32 Mixed seniors\n",
        "+ 33 Lower class large families\n",
        "+ 34 Large family, employed child\n",
        "+ 35 Village families\n",
        "+ 36 Couples with teens 'Married with children'\n",
        "+ 37 Mixed small town dwellers\n",
        "+ 38 Traditional families\n",
        "+ 39 Large religous families\n",
        "+ 40 Large family farms\n",
        "+ 41 Mixed rurals\n",
        "\n",
        "L1:\n",
        "\n",
        "+ 1 20-30 years\n",
        "+ 2 30-40 years\n",
        "+ 3 40-50 years\n",
        "+ 4 50-60 years\n",
        "+ 5 60-70 years\n",
        "+ 6 70-80 years\n",
        "\n",
        "\n",
        "L2:\n",
        "\n",
        "+ 1 Successful hedonists\n",
        "+ 2 Driven Growers\n",
        "+ 3 Average Family\n",
        "+ 4 Career Loners\n",
        "+ 5 Living well\n",
        "+ 6 Cruising Seniors\n",
        "+ 7 Retired and Religeous\n",
        "+ 8 Family with grown ups\n",
        "+ 9 Conservative families\n",
        "+ 10 Farmers\n",
        "\n",
        "\n",
        "L3:\n",
        "\n",
        "+ 0 0%\n",
        "+ 1 1 - 10%\n",
        "+ 2 11 - 23%\n",
        "+ 3 24 - 36%\n",
        "+ 4 37 - 49%\n",
        "+ 5 50 - 62%\n",
        "+ 6 63 - 75%\n",
        "+ 7 76 - 88%\n",
        "+ 8 89 - 99%\n",
        "+ 9 100%\n",
        "\n",
        "\n",
        "L4:\n",
        "\n",
        "+ 0 f 0\n",
        "+ 1 f 1 – 49\n",
        "+ 2 f 50 – 99\n",
        "+ 3 f 100 – 199\n",
        "+ 4 f 200 – 499\n",
        "+ 5 f 500 – 999\n",
        "+ 6 f 1000 – 4999\n",
        "+ 7 f 5000 – 9999\n",
        "+ 8 f 10.000 - 19.999\n",
        "+ 9 f 20.000 - ?\n",
        "\n",
        "\n",
        "\n",
        "FUENTE DE ESTA INFORMACIÓN: https://github.com/tezzytezzy/caravan-insurance-policy/blob/master/dictionary.txt"
      ],
      "metadata": {
        "id": "CiAFtYnOQl3-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in resultado.columns:\n",
        "  print(\"Columna: \", i, \", Enteros que la conforman: \", np.unique(resultado[i]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaUpeh1fFtiB",
        "outputId": "c7a858ef-57b3-4129-e9ab-9fc32c3582e4"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Columna:  0 , Enteros que la conforman:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 21 22 23 24 25\n",
            " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
            "Columna:  1 , Enteros que la conforman:  [ 1  2  3  4  5  6  7  8 10]\n",
            "Columna:  2 , Enteros que la conforman:  [1 2 3 4 5 6]\n",
            "Columna:  3 , Enteros que la conforman:  [1 2 3 4 5 6]\n",
            "Columna:  4 , Enteros que la conforman:  [ 1  2  3  4  5  6  7  8  9 10]\n",
            "Columna:  5 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  6 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  7 , Enteros que la conforman:  [0 1 2 3 4 5]\n",
            "Columna:  8 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  9 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  10 , Enteros que la conforman:  [0 1 2 3 4 5 6 7]\n",
            "Columna:  11 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  12 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  13 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  14 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  15 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  16 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  17 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  18 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  19 , Enteros que la conforman:  [0 1 2 3 4 5]\n",
            "Columna:  20 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  21 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  22 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  23 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  24 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  25 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  26 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  27 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  28 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  29 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  30 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  31 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  32 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 9]\n",
            "Columna:  33 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  34 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  35 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  36 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  37 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  38 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  39 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  40 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 9]\n",
            "Columna:  41 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  42 , Enteros que la conforman:  [1 2 3 4 5 6 7 8]\n",
            "Columna:  43 , Enteros que la conforman:  [0 1 2 3]\n",
            "Columna:  44 , Enteros que la conforman:  [0 1 2 3 4 5 6]\n",
            "Columna:  45 , Enteros que la conforman:  [0 1 2 3 4]\n",
            "Columna:  46 , Enteros que la conforman:  [0 4 5 6 7 8 9]\n",
            "Columna:  47 , Enteros que la conforman:  [0 5 6 7]\n",
            "Columna:  48 , Enteros que la conforman:  [0 3 4 5 6 7]\n",
            "Columna:  49 , Enteros que la conforman:  [0 4 6 7 9]\n",
            "Columna:  50 , Enteros que la conforman:  [0 1 2 3 4 5]\n",
            "Columna:  51 , Enteros que la conforman:  [0 3 4 5 6 7]\n",
            "Columna:  52 , Enteros que la conforman:  [0 1 2 3 4 6]\n",
            "Columna:  53 , Enteros que la conforman:  [0 2 3 4 5 6]\n",
            "Columna:  54 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8 9]\n",
            "Columna:  55 , Enteros que la conforman:  [0 1 2 3 4 5 6]\n",
            "Columna:  56 , Enteros que la conforman:  [0 2 3]\n",
            "Columna:  57 , Enteros que la conforman:  [0 4 5 6 7]\n",
            "Columna:  58 , Enteros que la conforman:  [0 1 2 3 4 5 6 7 8]\n",
            "Columna:  59 , Enteros que la conforman:  [0 1 2 3]\n",
            "Columna:  60 , Enteros que la conforman:  [0 1 2 3 4 5 6]\n",
            "Columna:  61 , Enteros que la conforman:  [0 1]\n",
            "Columna:  62 , Enteros que la conforman:  [0 1 2 3 4 5 6]\n",
            "Columna:  63 , Enteros que la conforman:  [0 2 3 4 5]\n",
            "Columna:  64 , Enteros que la conforman:  [0 1 2]\n",
            "Columna:  65 , Enteros que la conforman:  [0 1 5]\n",
            "Columna:  66 , Enteros que la conforman:  [0 1]\n",
            "Columna:  67 , Enteros que la conforman:  [ 0  1  2  3  4  5  6  7 12]\n",
            "Columna:  68 , Enteros que la conforman:  [0 1 2 3 4 5]\n",
            "Columna:  69 , Enteros que la conforman:  [0 1 2 3 8]\n",
            "Columna:  70 , Enteros que la conforman:  [0 1 2 3 4]\n",
            "Columna:  71 , Enteros que la conforman:  [0 1 2 3]\n",
            "Columna:  72 , Enteros que la conforman:  [0 1 2 3 4 5 6]\n",
            "Columna:  73 , Enteros que la conforman:  [0 1 2 3 4 6]\n",
            "Columna:  74 , Enteros que la conforman:  [0 1 2 3]\n",
            "Columna:  75 , Enteros que la conforman:  [0 1 2 3 4 5 8]\n",
            "Columna:  76 , Enteros que la conforman:  [0 1]\n",
            "Columna:  77 , Enteros que la conforman:  [0 1]\n",
            "Columna:  78 , Enteros que la conforman:  [0 1 2]\n",
            "Columna:  79 , Enteros que la conforman:  [0 1 2 3 4 5 6 7]\n",
            "Columna:  80 , Enteros que la conforman:  [0 1]\n",
            "Columna:  81 , Enteros que la conforman:  [0 1 2]\n",
            "Columna:  82 , Enteros que la conforman:  [0 1 2 3 4]\n",
            "Columna:  83 , Enteros que la conforman:  [0 1 2]\n",
            "Columna:  84 , Enteros que la conforman:  [0 1 2]\n",
            "Columna:  85 , Enteros que la conforman:  [0 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se cuenta con un DataSet mixto. Según el diccionario, las columnas númericas son la 1, 2 y desde la 64 a la 84.\n",
        "\n",
        "Por otra parte, las demás columnas son categóricas, y están codificadas según ciertos valores.\n",
        "\n",
        "Con los valores de L0 tenemos a la columna 0.\n",
        "\n",
        "Con los valores L1 tenemos a la columna 3.\n",
        "\n",
        "Con los valores L2 tenemos a la columna 4.\n",
        "\n",
        "Con los valores L3 tenemos desde la columna  5 a la 42.\n",
        "\n",
        "Con los valores L4 tenemos desde la columna 43 a la 63.\n",
        "\n",
        "La cuestión que va a ser discutida más adelante, es si, las columnas categóricas van a ser transformadas con one-hot o se trasnformarán según otro método."
      ],
      "metadata": {
        "id": "uGyqcVX-UPWv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>1)  Analizar y describir adecuadamente el problema a resolver. Identificar los elementos $X$, $Y$ and $f$ del problema, y describirlos en detalle. 0.5 puntos. "
      ],
      "metadata": {
        "id": "Y2HSMffMUP10"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras el análisis detalaldo del DataSet hecho anteriormente, se pueden determinar fácilmente los elementos del problema que nos compete.\n",
        "\n",
        "**X** sería el conjunto de filas del dataset sin tener en cuenta la última columna, que es el objetivo. Cada fila de X consta de 85 columnas, representando información de forma numérica (con enteros) o con información categórica según el grupo de columnas, para las cuales se pensará una transformación más adelante.\n",
        "\n",
        "**Y** sería la variable objetivo. En este caso queremos clasificar si dado un caso de X, este tendrá o no tendrá poliza.\n",
        "\n",
        "**f** es la función desconocida para nosotros que asigna a cada elemento de X su correspondiente etiqueta en Y de forma correcta. Esta es la función que se pretende estimar."
      ],
      "metadata": {
        "id": "1YYJ7NzqVfn9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hay una regla principal para evitar malas prácticas como el data snooping, que es dividir el conjunto de Test antes de extraer cualquier tipo de información de los datos, y no tocarlo más hasta finalizar el entrenamiento, para usarlo únicamente para estimar el Eout, sin que influya en ningún momento (directa ni indirectamente) en nuestro entrenamiento. Así pues, vamos a dividirlo ya y a almacenarlo en una variable diferente que no se volverá a tocar hasta entonces."
      ],
      "metadata": {
        "id": "rUdeCPJ6XIu_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "pd_data = resultado.drop(resultado.columns[-1], axis=1)\n",
        "pd_labels = resultado[85]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(pd_data, pd_labels, test_size=0.20, random_state=33)\n",
        "print('Train: ', X_train.shape, y_train.shape)\n",
        "print('Test: ', X_test.shape, y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vvx6fAsdYYLD",
        "outputId": "488970f9-2d55-4332-fbcb-72e9b3586940"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train:  (7857, 85) (7857,)\n",
            "Test:  (1965, 85) (1965,)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que tampoco se dispone de una cantidad exagerada de datos, se ha optado por un tamaño de un 20% del DataSet para Test, dado que necesitamos un valor Eout confiable en base a los 9000 datos que se tienen de partida."
      ],
      "metadata": {
        "id": "Lb-GDiXiYx8O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se va a realizar un análisis de la relación entre los diferentes atributos y la salida en busca de patrones y correlaciones. Este análisis nos ayudará a comprender cómo están relacionados entre sí y cómo se correlacionan con la variable de salida. Esta información será útil en el proceso de preprocesamiento de los datos. Además, podremos extraer estadísticas que nos permitan identificar comportamientos anómalos o consideraciones importantes.\n",
        "\n",
        "El objetivo principal de este análisis es determinar si existen patrones o comportamientos específicos en los datos que debamos tener en cuenta durante el preprocesamiento. Por ejemplo, si una variable muestra un comportamiento sinusoidal, podríamos aplicar una transformación seno-coseno. Si una variable se encuentra dentro de un rango pequeño y constante, podríamos evitar la normalización o utilizar un método de normalización adecuado. También podemos identificar variables que sean independientes de la variable de salida y que podrían eliminarse del conjunto de datos."
      ],
      "metadata": {
        "id": "2seR-dKEaNCC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo primero será mostrar el porcentaje de 1's y 0's que hay en nuestras etiquetas, para lo cual se usará la típica gráfica coloquialmente conocida como de \"quesitos\"."
      ],
      "metadata": {
        "id": "xHQaTCHoa_tp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Vector de etiquetas\n",
        "etiquetas = [0,1]\n",
        "\n",
        "# Valores para cada etiqueta\n",
        "y = y_train.to_numpy()\n",
        "valores = [len(np.where(y==0)[0]), len(np.where(y==1)[0])]\n",
        "# Crear la gráfica de quesos\n",
        "plt.pie(valores, labels=etiquetas, autopct='%1.1f%%', startangle=90)\n",
        "\n",
        "# Añadir un título\n",
        "plt.title('Distribución de etiquetas')\n",
        "\n",
        "# Mostrar la gráfica\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 429
        },
        "id": "Q9h-NSccbKmk",
        "outputId": "3c6fd748-1649-4e56-b19c-6c8e61ce5c6d"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, nuestros datos estan muy desbalanceados, esto es un gran problema, pues nubla mucho el verdadero buen funcionamiento de un algoritmo. Por ejemplo, un clasificador que siempre clasifique como '0', ya tendría un 94% de aciertos. Esto es, realmente, natural. No podemos esperar una partición equitativa de los datos, menos aún en un caso como este, donde es lógico que el porcentaje de clientes que tienen un cierto tipo de póliza es muy bajo. Así pues, esto nos indica simplemente que tendremos que ir con mucho ojo analizando los resultados, teniendo en cuenta esta información, evitando caer en falsas conclusiones y verificando que nuestra solución verdaderamente está intentando predecir, y no solo usando la estadística a su favor. Este apartado se abordará más detenidamente cuando se seleccionen las métricas a usar para el problema."
      ],
      "metadata": {
        "id": "2HFMFQEVdW93"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Lo segundo será mostrar una gráfica acerca de 5 de las columnas categóricas que hay en el dataset. Mostrarlas todas sería muy extenso y tedioso para el lector, así que se imprime una de cada tipo."
      ],
      "metadata": {
        "id": "01ZKswaaaRXP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def display_categorico(data, labels, clase1, clase2, title='', categorias=[]):\n",
        "  atributo = data.columns[0]\n",
        "  data = np.array(data).flatten()\n",
        "  labels = np.array(labels)\n",
        "  valores = np.unique(data)\n",
        "  print('Los valores que tiene este atributo son: ', valores)\n",
        "  print()  \n",
        "\n",
        "  if len(categorias) > 0 : valores = np.array(categorias)\n",
        "\n",
        "  num_valor = np.zeros_like(valores, dtype=np.int_)\n",
        "  for i in range(len(valores)):\n",
        "    num_valor[i] = np.count_nonzero(data == valores[i])\n",
        "\n",
        "  data_clase1 = np.array([data[i] for i, xi in enumerate(data) if labels[i] == clase1])\n",
        "  data_clase2 = np.array([data[i] for i, xi in enumerate(data) if labels[i] == clase2])\n",
        "\n",
        "  num_clase1 = data_clase1.shape[0]\n",
        "  num_clase2 = data_clase2.shape[0]\n",
        "\n",
        "\n",
        "  print('Para cada atributo: la cantidad de ', clase1, ' y la cantidad de ', clase2, ', así como sus porcentajes:')\n",
        "  x_clase1 = np.zeros_like(valores, dtype=np.float64)\n",
        "  x_clase2 = np.zeros_like(valores, dtype=np.float64)\n",
        "  for i in range(len(x_clase1)):\n",
        "    x_clase1[i] = np.count_nonzero(data_clase1 == valores[i])/num_valor[i]\n",
        "    x_clase2[i] = np.count_nonzero(data_clase2 == valores[i])/num_valor[i]\n",
        "    print(valores[i], ': ', np.count_nonzero(data_clase1 == valores[i]),' (un ', x_clase1[i]*100, '%) de ', clase1, 'y ', np.count_nonzero(data_clase2 == valores[i]), ' (un ', x_clase2[i]*100, '%) de ', clase2)\n",
        "  print()\n",
        "\n",
        "\n",
        "  y = valores\n",
        "  fig,ax = plt.subplots()\n",
        "  ax.plot(x_clase1, y, 'r-', markersize=10, label = clase1)\n",
        "  ax.plot(x_clase2, y, 'b-', markersize=10, label = clase2)\n",
        "  ax.legend()\n",
        "  ax.set(title=title)\n",
        "  ax.set_xlabel('Porcentaje de la Población')\n",
        "  ax.set_ylabel(atributo);\n",
        "\n",
        "  plt.show()"
      ],
      "metadata": {
        "id": "1iNB5UazaaJg"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "display_categorico(X_train[[0]], y_train, 0, 1, 'Porción de personas con poliza en función del subtipo de cliente' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "cg8v1u_5d2wK",
        "outputId": "ca27f3e3-7cf7-4444-c8af-651628a0cf9b"
      },
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores que tiene este atributo son:  [ 1  2  3  4  5  6  7  8  9 10 11 12 13 15 16 17 18 19 20 21 22 23 24 25\n",
            " 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41]\n",
            "\n",
            "Para cada atributo: la cantidad de  0  y la cantidad de  1 , así como sus porcentajes:\n",
            "1 :  154  (un  87.00564971751412 %) de  0 y  23  (un  12.994350282485875 %) de  1\n",
            "2 :  102  (un  91.8918918918919 %) de  0 y  9  (un  8.108108108108109 %) de  1\n",
            "3 :  322  (un  93.6046511627907 %) de  0 y  22  (un  6.395348837209303 %) de  1\n",
            "4 :  73  (un  97.33333333333334 %) de  0 y  2  (un  2.666666666666667 %) de  1\n",
            "5 :  56  (un  96.55172413793103 %) de  0 y  2  (un  3.4482758620689653 %) de  1\n",
            "6 :  142  (un  86.06060606060606 %) de  0 y  23  (un  13.939393939393941 %) de  1\n",
            "7 :  51  (un  92.72727272727272 %) de  0 y  4  (un  7.2727272727272725 %) de  1\n",
            "8 :  383  (un  86.45598194130926 %) de  0 y  60  (un  13.544018058690746 %) de  1\n",
            "9 :  356  (un  97.26775956284153 %) de  0 y  10  (un  2.73224043715847 %) de  1\n",
            "10 :  195  (un  91.98113207547169 %) de  0 y  17  (un  8.018867924528301 %) de  1\n",
            "11 :  208  (un  94.97716894977168 %) de  0 y  11  (un  5.0228310502283104 %) de  1\n",
            "12 :  137  (un  85.625 %) de  0 y  23  (un  14.374999999999998 %) de  1\n",
            "13 :  214  (un  92.24137931034483 %) de  0 y  18  (un  7.758620689655173 %) de  1\n",
            "15 :  6  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "16 :  17  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "17 :  11  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "18 :  21  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "19 :  5  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "20 :  32  (un  96.96969696969697 %) de  0 y  1  (un  3.0303030303030303 %) de  1\n",
            "21 :  24  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "22 :  142  (un  97.93103448275862 %) de  0 y  3  (un  2.0689655172413794 %) de  1\n",
            "23 :  295  (un  98.66220735785953 %) de  0 y  4  (un  1.3377926421404682 %) de  1\n",
            "24 :  257  (un  98.09160305343512 %) de  0 y  5  (un  1.9083969465648856 %) de  1\n",
            "25 :  97  (un  97.0 %) de  0 y  3  (un  3.0 %) de  1\n",
            "26 :  61  (un  96.82539682539682 %) de  0 y  2  (un  3.1746031746031744 %) de  1\n",
            "27 :  60  (un  98.36065573770492 %) de  0 y  1  (un  1.639344262295082 %) de  1\n",
            "28 :  37  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "29 :  108  (un  95.57522123893806 %) de  0 y  5  (un  4.424778761061947 %) de  1\n",
            "30 :  146  (un  97.98657718120806 %) de  0 y  3  (un  2.013422818791946 %) de  1\n",
            "31 :  248  (un  96.12403100775194 %) de  0 y  10  (un  3.875968992248062 %) de  1\n",
            "32 :  178  (un  96.21621621621622 %) de  0 y  7  (un  3.783783783783784 %) de  1\n",
            "33 :  1070  (un  94.19014084507043 %) de  0 y  66  (un  5.809859154929577 %) de  1\n",
            "34 :  257  (un  95.8955223880597 %) de  0 y  11  (un  4.104477611940299 %) de  1\n",
            "35 :  276  (un  96.16724738675958 %) de  0 y  11  (un  3.8327526132404177 %) de  1\n",
            "36 :  270  (un  91.83673469387756 %) de  0 y  24  (un  8.16326530612245 %) de  1\n",
            "37 :  172  (un  91.97860962566845 %) de  0 y  15  (un  8.02139037433155 %) de  1\n",
            "38 :  415  (un  93.04932735426009 %) de  0 y  31  (un  6.950672645739911 %) de  1\n",
            "39 :  408  (un  93.36384439359267 %) de  0 y  29  (un  6.636155606407322 %) de  1\n",
            "40 :  112  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "41 :  274  (un  96.47887323943662 %) de  0 y  10  (un  3.5211267605633805 %) de  1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_categorico(X_train[[3]], y_train, 0, 1, 'Porción de personas con poliza en función del subtipo de cliente' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "tsIgcra1kDSl",
        "outputId": "6c7bd0ce-0d4c-4056-a9ed-cdbfb948f093"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores que tiene este atributo son:  [1 2 3 4 5 6]\n",
            "\n",
            "Para cada atributo: la cantidad de  0  y la cantidad de  1 , así como sus porcentajes:\n",
            "1 :  81  (un  98.78048780487805 %) de  0 y  1  (un  1.2195121951219512 %) de  1\n",
            "2 :  1777  (un  93.4279705573081 %) de  0 y  125  (un  6.572029442691902 %) de  1\n",
            "3 :  3932  (un  94.24736337488015 %) de  0 y  240  (un  5.752636625119846 %) de  1\n",
            "4 :  1319  (un  93.87900355871886 %) de  0 y  86  (un  6.120996441281139 %) de  1\n",
            "5 :  244  (un  95.3125 %) de  0 y  12  (un  4.6875 %) de  1\n",
            "6 :  39  (un  97.5 %) de  0 y  1  (un  2.5 %) de  1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_categorico(X_train[[4]], y_train, 0, 1, 'Porción de personas con poliza en función del subtipo de cliente' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "flxT73-fkIE1",
        "outputId": "13281101-7498-4cae-ed8f-9abbd3e82f60"
      },
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores que tiene este atributo son:  [ 1  2  3  4  5  6  7  8  9 10]\n",
            "\n",
            "Para cada atributo: la cantidad de  0  y la cantidad de  1 , así como sus porcentajes:\n",
            "1 :  707  (un  92.41830065359477 %) de  0 y  58  (un  7.5816993464052285 %) de  1\n",
            "2 :  576  (un  86.87782805429865 %) de  0 y  87  (un  13.122171945701359 %) de  1\n",
            "3 :  1110  (un  93.35576114381834 %) de  0 y  79  (un  6.644238856181666 %) de  1\n",
            "4 :  60  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "5 :  750  (un  98.2961992136304 %) de  0 y  13  (un  1.7038007863695939 %) de  1\n",
            "6 :  255  (un  97.70114942528735 %) de  0 y  6  (un  2.2988505747126435 %) de  1\n",
            "7 :  680  (un  96.45390070921985 %) de  0 y  25  (un  3.546099290780142 %) de  1\n",
            "8 :  2045  (un  94.15285451197053 %) de  0 y  127  (un  5.847145488029466 %) de  1\n",
            "9 :  823  (un  93.20498301245753 %) de  0 y  60  (un  6.795016987542468 %) de  1\n",
            "10 :  386  (un  97.47474747474747 %) de  0 y  10  (un  2.525252525252525 %) de  1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_categorico(X_train[[5]], y_train, 0, 1, 'Porción de personas con poliza en función del subtipo de cliente' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 736
        },
        "id": "rcPo271GkKx5",
        "outputId": "84ac0014-15ac-4535-9928-6f951f602ee5"
      },
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores que tiene este atributo son:  [0 1 2 3 4 5 6 7 8 9]\n",
            "\n",
            "Para cada atributo: la cantidad de  0  y la cantidad de  1 , así como sus porcentajes:\n",
            "0 :  4111  (un  94.54921803127874 %) de  0 y  237  (un  5.450781968721251 %) de  1\n",
            "1 :  2036  (un  93.65225390984361 %) de  0 y  138  (un  6.347746090156393 %) de  1\n",
            "2 :  906  (un  92.54341164453524 %) de  0 y  73  (un  7.456588355464761 %) de  1\n",
            "3 :  190  (un  95.0 %) de  0 y  10  (un  5.0 %) de  1\n",
            "4 :  93  (un  96.875 %) de  0 y  3  (un  3.125 %) de  1\n",
            "5 :  24  (un  96.0 %) de  0 y  1  (un  4.0 %) de  1\n",
            "6 :  16  (un  88.88888888888889 %) de  0 y  2  (un  11.11111111111111 %) de  1\n",
            "7 :  6  (un  85.71428571428571 %) de  0 y  1  (un  14.285714285714285 %) de  1\n",
            "8 :  3  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "9 :  7  (un  100.0 %) de  0 y  0  (un  0.0 %) de  1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display_categorico(X_train[[43]], y_train, 0, 1, 'Porción de personas con poliza en función del subtipo de cliente' )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 632
        },
        "id": "s6qyip9kkMS7",
        "outputId": "48a0be96-a111-411b-99e5-c1d41f70c17a"
      },
      "execution_count": 108,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Los valores que tiene este atributo son:  [0 1 2 3]\n",
            "\n",
            "Para cada atributo: la cantidad de  0  y la cantidad de  1 , así como sus porcentajes:\n",
            "0 :  4510  (un  95.73338993844195 %) de  0 y  201  (un  4.2666100615580556 %) de  1\n",
            "1 :  259  (un  95.5719557195572 %) de  0 y  12  (un  4.428044280442804 %) de  1\n",
            "2 :  2611  (un  91.2937062937063 %) de  0 y  249  (un  8.706293706293707 %) de  1\n",
            "3 :  12  (un  80.0 %) de  0 y  3  (un  20.0 %) de  1\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como nos daremos cuenta, los datos están desbalanceados. Hay valores que tienen muchisimos más ejemplos que otros. Esto será una constante en todos los atributos que analicemos, y no es realmente un problema con el que podamos lidiar. Aun así, esto no es problema a no ser que haya un desbalanceo extremo donde, por ejemplo, el 90% de los datos sean del mismo tipo. Aún con esas, no podríamos hacer mucho más que tenerlo en cuenta a la hora del análisis de resultados."
      ],
      "metadata": {
        "id": "n90lv06akUwA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "No se aprecia una tendencia o relacion comentable entre los valores del atributo. Sin ninguna duda, se recomienda, a la hora del preprocesado, usar un one-hot encoding clásico. Esto hará crecer el número de columnas presentes en el DataSet, pero se usará alguna alternativa a PCA (no es bueno usarlo con DataSets mixtos) para la extracción de columnas importantes."
      ],
      "metadata": {
        "id": "cf4WEKrUkfIa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se podría pensar en dejar L1, L3 y L4 como están, al considerar un orden dentro de las categorías que representan. No obstante, esto será discutido en el apartado de transformación de los datos. También se ha descartado el hecho de observar variables numéricas para alguna transformación. Podría resultar interesante en los propios casos, pero se ha optado por transformar los atributos necesarios y dejar al algoritmo de clasificación trabajar.\n",
        "\n",
        "Finalmente, tampoco se comenta nada acerca de variables binarias, pero es que, sencillamanete, no hay. Tras leer la información del DataSet, se puede determinar y cualquier coincidencia (alguna columna donde solo aparezcan 0's y 1's), es fruto de los datos que se nos han proporcionado."
      ],
      "metadata": {
        "id": "u_tljYkFNTIZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>2)  Identificar qué conjuntos de hipótesis se emplearán y justificar dicha elección. 0.25 puntos. "
      ],
      "metadata": {
        "id": "9Ozk6Bf-fid4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para esta práctica, tenemos la opción de elegir entre cuatro modelos lineales que hemos aprendido: Regresión Lineal, Regresión Logística, PLA y PLA+Pocket. Sin embargo, dado que estamos frente a un problema de clasificación, es recomendable descartar la Regresión Lineal, ya que existen técnicas específicamente diseñadas para la clasificación.\n",
        "\n",
        "Además, podemos descartar el algoritmo PLA, ya que solo funciona bien con datos linealmente separables y, en general, el PLA+Pocket es considerado superior, ya que busca mantener la mejor solución obtenida hasta el momento.\n",
        "\n",
        "En resumen, los dos modelos lineales que utilizaremos para abordar este problema de clasificación serán PLA+Pocket y Regresión Logística. Ambos algoritmos son eficaces en este tipo de problemas y han demostrado brindar resultados satisfactorios en prácticas anteriores."
      ],
      "metadata": {
        "id": "0GVqF5eNFGAb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>3)  Si la base de datos define conjuntos de training y test, únalos en un solo conjunto y genere sus propios conjuntos. Describa y justifique el mecanismo de partición. 0.75 puntos. "
      ],
      "metadata": {
        "id": "4LiijYn4fw_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En el proceso de preparación del conjunto de entrenamiento, se realizará una validación cruzada de 5-fold. Esto implica dividir el conjunto de ejemplos en 5 grupos de manera estratificada, asegurando que cada grupo contenga una proporción equitativa de todas las clases presentes. Luego se llevarán a cabo 5 iteraciones, en cada una de las cuales se utilizarán 4 grupos como conjunto de entrenamiento y el grupo restante como conjunto de validación.\n",
        "\n",
        "La validación cruzada se emplea para evaluar el rendimiento de los algoritmos de clasificación de forma más confiable. Aunque un algoritmo puede tener suerte y mostrar un buen desempeño en una única división de los datos de entrenamiento y validación, esto no garantiza su capacidad real para generalizar a nuevos conjuntos de datos. Al realizar múltiples divisiones y entrenar el algoritmo en diferentes configuraciones de datos, se obtienen medidas de error en cada iteración.\n",
        "\n",
        "La elección de 5 validaciones se basa en la necesidad de reducir el impacto del azar en los resultados de validación. A veces, los resultados pueden verse afectados por variaciones aleatorias en la selección de los datos de entrenamiento y validación. Al realizar 5 validaciones con diferentes particiones, se obtiene una medida más robusta del rendimiento promedio del algoritmo. La media de los resultados de validación proporciona una estimación más confiable de la capacidad del algoritmo para clasificar los datos.\n",
        "\n",
        "Un inconveniente de este enfoque es que reduce el tamaño del conjunto de entrenamiento utilizado para la validación. Sin embargo, dado que se dispone de un conjunto de datos razonablamente grande, este inconveniente se puede mitigar, ya que aún se cuenta con una cantidad suficiente de ejemplos para entrenar y evaluar el rendimiento de los algoritmos de clasificación."
      ],
      "metadata": {
        "id": "cRPuk0VIHGal"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#5-fold cross validation\n",
        "particiones = np.empty((5),list)\n",
        "\n",
        "train_data = X_train.to_numpy()\n",
        "train_labels = y_train.to_numpy()\n",
        "\n",
        "index_train = np.arange(len(train_labels))\n",
        "\n",
        "index_yes = np.array([indice for indice in index_train if train_labels[indice] == 1])\n",
        "index_no = np.array([indice for indice in index_train if train_labels[indice] == 0])\n",
        "\n",
        "\n",
        "for i in range(5):\n",
        "  particiones[i] = []\n",
        "\n",
        "#En vez de tener varios conjuntos de datos, usaremos conjuntos de índices\n",
        "for i in range(index_yes.shape[0]):\n",
        "  particiones[i%5].append(index_yes[i])\n",
        "for i in range(index_no.shape[0]):\n",
        "  particiones[i%5].append(index_no[i])\n",
        "  \n",
        "for i in range(5):\n",
        "  particiones[i] = np.asarray(particiones[i])\n",
        "  np.random.shuffle(particiones[i])\n",
        "\n",
        "training1 = np.concatenate((particiones[0],particiones[1],particiones[2],particiones[3]))\n",
        "test1 = particiones[4]\n",
        "\n",
        "training2 = np.concatenate((particiones[4],particiones[0],particiones[1],particiones[2]))\n",
        "test2 = particiones[3]\n",
        "\n",
        "training3 = np.concatenate((particiones[3],particiones[4],particiones[0],particiones[1]))\n",
        "test3 = particiones[2]\n",
        "\n",
        "training4 = np.concatenate((particiones[2],particiones[3],particiones[4],particiones[0]))\n",
        "test4 = particiones[1]\n",
        "\n",
        "training5 = np.concatenate((particiones[1],particiones[2],particiones[3],particiones[4]))\n",
        "test5 = particiones[0]\n",
        "\n",
        "cv_trains = [training1,training2,training3,training4,training5]\n",
        "cv_tests = [test1,test2,test3,test4,test5]\n"
      ],
      "metadata": {
        "id": "Lm9cT0xof1-D"
      },
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>4)  Justifique todos los detalles del preprocesado de los datos (codificación, transformación, normalización, etc). Es decir, todas las manipulaciones sobre los datos iniciales que nos permitan fijar el conjunto de vectores de características que se usarán en el entrenamiento. 1 punto.  \n",
        "\n",
        "<font color='blue'>Nota: Las transformaciones no-lineales de las variables pueden definirse a partir de las potencias y\n",
        "productos de potencias de las variables originales, conjuntos de polinomios ortogonales, etc. Si se\n",
        "usan transformaciones no polinómicas de las variable como $log$, $\\sqrt{()}$, $sin$, etc, debe justificar el\n",
        "interés de las mismas. "
      ],
      "metadata": {
        "id": "qJykJiQxf30a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aunque sería más adecuado realizar el preprocesado antes de dividir el conjunto de entrenamiento con la validación cruzada (para evitar tener que repetirlo varias veces), he optado por hacerlo a continuación para seguir el formato establecido en la práctica. Además, al elegir particionar por índices en lugar de crear conjuntos de ejemplos separados para cada partición, puedo modificar directamente el conjunto de entrenamiento sin afectar las particiones correspondientes."
      ],
      "metadata": {
        "id": "PYXJXJo6Eczx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.preprocessing import OneHotEncoder"
      ],
      "metadata": {
        "id": "XUXvx9_5gMlM"
      },
      "execution_count": 110,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "La siguiente función hace one_hot_encoding de la columna que se le pase como parámetro y según las categorías que se pasen como parámetro. Se hace esto porque la versión de sklearn para OneHot, crea columnas extras para las categorías que están en la columna, y obvia las que no están. Como se pensó, que si alguna categoría no aparece en train, pero si en test, se estaría omitiendo información al eliminarla, se ha optado por crear columnas de 0's si esto ocurre. No obstante, se podría probar a hacer ambas cosas y ver cuales da mejores resulados, pero por razones de tiempo, me veo obligado a continuar con esta idea."
      ],
      "metadata": {
        "id": "Pw4jdiwJEgFi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pandas.core.indexes.category import contains\n",
        "def aplicar_one_hot_encoding(data, columna, categorias):\n",
        "    # Realiza el one-hot encoding en la columna especificada usando las categorías proporcionadas\n",
        "    columna_encoded = pd.get_dummies(data[columna], prefix=columna, columns=categorias)\n",
        "    # Encuentra las categorías faltantes en la lista de categorías\n",
        "    aniade = columna + '_'\n",
        "    for i,st in enumerate(categorias):\n",
        "      categorias[i] = aniade + str(st)\n",
        "\n",
        "    categorias_faltantes = set(categorias) - set(columna_encoded.columns)\n",
        "\n",
        "    # Crea columnas adicionales para las categorías faltantes y se rellenan con 0\n",
        "    for categoria_faltante in categorias_faltantes:\n",
        "        columna_nueva = columna + '_' + str(categoria_faltante)\n",
        "        columna_encoded[columna_nueva] = 0\n",
        "\n",
        "    # Concatena la columna codificada al conjunto de datos original\n",
        "    data_encoded = pd.concat([data, columna_encoded], axis=1)\n",
        "\n",
        "    #Elimina la columna original\n",
        "    data_encoded = data_encoded.drop(columna, axis=1)\n",
        "\n",
        "    return data_encoded"
      ],
      "metadata": {
        "id": "jM6k51X_dh-D"
      },
      "execution_count": 111,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Por comodidad, se cambian todos los índices a string, vendrá mejor para tratamientos posteriores que se harán."
      ],
      "metadata": {
        "id": "-njC-BsdQIOv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns = X_train.columns.astype(str)\n"
      ],
      "metadata": {
        "id": "ptSuwfNBQZb5"
      },
      "execution_count": 112,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tras realizar one-hot encoding, se pasará a normalizar las columnas numéricas (1,2 y de la 64 a la 84). Hay que tener en cuenta que cuentan con diferentes rangos. Para normalizar, se optará por un min max scaler para dejar las columnas entre 0 y 1. Aquí tampoco se ha optado por la función predefinida en sklearn, puesto que normaliza en base al minimo y al máximo presente en la columna.\n",
        "\n",
        "Dado que si se echa un vistazo al diccionario del DataSet, tenemos rangos de valores posibles para las columnas numéricas, la normalización se hará en base al máximo y al mínimo de ese rango."
      ],
      "metadata": {
        "id": "FA-iG4aGmJCU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "def aplicar_min_max_scaler(data, columnas, max, min):\n",
        "    for i in columnas:\n",
        "      data[i] = (data[i]-min)/(max - min)\n",
        "      data[i] = data[i] * (1-0)+0\n",
        "\n",
        "    # scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "    # data[columnas] = scaler.fit_transform(data[columnas])\n",
        "    return data\n",
        "\n",
        "columnas3 = [str(i) for i in range(64,85,1)]\n",
        "columnas1 = ['1']\n",
        "columnas2 = ['2']\n",
        "\n",
        "#Se normaliza tomando como máximo y mínimo los que se nos dan en la información del dataset\n",
        "X_train = aplicar_min_max_scaler(X_train, columnas1, 6, 1)\n",
        "X_train = aplicar_min_max_scaler(X_train, columnas2, 10, 1)\n",
        "X_train = aplicar_min_max_scaler(X_train, columnas3, 12, 1)\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "NGU6dbAVoIZ2",
        "outputId": "0bc1022f-a9be-4086-e9f1-8e34a1f1b79f"
      },
      "execution_count": 113,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       0    1         2  3  4  5  6  7  8  9  ...        75        76  \\\n",
              "559   26  0.4  0.111111  4  6  0  3  0  6  5  ... -0.090909 -0.090909   \n",
              "771   37  0.0  0.222222  3  8  9  0  0  0  6  ... -0.090909 -0.090909   \n",
              "4701   9  0.0  0.333333  2  3  2  3  1  5  7  ... -0.090909 -0.090909   \n",
              "3315  33  0.0  0.222222  3  8  0  4  1  5  6  ... -0.090909 -0.090909   \n",
              "5133  10  0.0  0.222222  2  3  0  6  2  1  7  ... -0.090909 -0.090909   \n",
              "...   ..  ...       ... .. .. .. .. .. .. ..  ...       ...       ...   \n",
              "57    12  0.0  0.222222  2  3  0  6  0  3  7  ... -0.090909 -0.090909   \n",
              "578   33  0.0  0.111111  3  8  0  7  2  0  9  ... -0.090909 -0.090909   \n",
              "26    12  0.0  0.333333  2  3  0  7  2  0  9  ... -0.090909 -0.090909   \n",
              "2439  38  0.0  0.222222  3  9  1  6  2  2  7  ... -0.090909 -0.090909   \n",
              "1366   8  0.0  0.222222  3  2  0  4  1  4  6  ... -0.090909 -0.090909   \n",
              "\n",
              "            77        78        79        80        81        82        83  \\\n",
              "559  -0.090909 -0.090909  0.000000 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "771  -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "4701 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "3315 -0.090909 -0.090909  0.000000 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "5133 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "57   -0.090909  0.000000  0.000000 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "578  -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "26   -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "2439 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "1366 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909 -0.090909   \n",
              "\n",
              "            84  \n",
              "559  -0.090909  \n",
              "771  -0.090909  \n",
              "4701 -0.090909  \n",
              "3315 -0.090909  \n",
              "5133 -0.090909  \n",
              "...        ...  \n",
              "57   -0.090909  \n",
              "578  -0.090909  \n",
              "26   -0.090909  \n",
              "2439 -0.090909  \n",
              "1366 -0.090909  \n",
              "\n",
              "[7857 rows x 85 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-403cd042-01df-4a16-8e3e-d06851737b2b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>75</th>\n",
              "      <th>76</th>\n",
              "      <th>77</th>\n",
              "      <th>78</th>\n",
              "      <th>79</th>\n",
              "      <th>80</th>\n",
              "      <th>81</th>\n",
              "      <th>82</th>\n",
              "      <th>83</th>\n",
              "      <th>84</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>26</td>\n",
              "      <td>0.4</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>37</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3315</th>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5133</th>\n",
              "      <td>10</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>33</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3</td>\n",
              "      <td>8</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>12</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>38</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "      <td>-0.090909</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7857 rows × 85 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-403cd042-01df-4a16-8e3e-d06851737b2b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-403cd042-01df-4a16-8e3e-d06851737b2b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-403cd042-01df-4a16-8e3e-d06851737b2b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las columnas numéricas que acaban de ser normalizadas se extraen a un dataset complementario para poder aplicarle la técnica PCA."
      ],
      "metadata": {
        "id": "k0Iu9lUHFs4j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "numericos = X_train.iloc[:, [1, 2] + [i for i in range(64,85,1)]]\n"
      ],
      "metadata": {
        "id": "7OhYmtrEV4iJ"
      },
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se aplica PCA a los numéricos. \n",
        "\n",
        "\n",
        "\n",
        "PCA (Principal Component Analysis) es un algoritmo estadístico ampliamente utilizado para reducir la dimensionalidad de un conjunto de datos mientras se conserva la mayor cantidad posible de información. Su objetivo es encontrar nuevas variables, llamadas componentes principales, que sean combinaciones lineales de las variables originales.\n",
        "\n",
        "En la implementación de PCA en la biblioteca scikit-learn (sklearn), se considera como un algoritmo de aprendizaje, pero en realidad no realiza un aprendizaje en el sentido tradicional. En su lugar, se utiliza el conjunto de datos de entrenamiento para calcular los componentes principales, y luego se puede aplicar la misma transformación a otros conjuntos de datos, como los conjuntos de datos de prueba.\n",
        "\n",
        "Al aplicar PCA, obtenemos un nuevo conjunto de datos que tiene menos dimensiones que el conjunto de datos original. Esto se logra al eliminar las dimensiones que tienen menos variabilidad o contribuyen menos a la estructura global de los datos. Sin embargo, es importante destacar que PCA no garantiza que no se pierda información en el proceso de reducción de dimensionalidad, pero intenta minimizar dicha pérdida.\n",
        "\n",
        "Si deseamos especificar cuántas dimensiones queremos en el conjunto de datos transformado, podemos indicar el número deseado al aplicar PCA. De lo contrario, PCA calculará automáticamente el número de dimensiones necesarias para mantener la mayor cantidad de información posible.\n",
        "\n",
        "Además, PCA también permite realizar una transformación inversa, lo que significa que podemos recuperar los datos originales (o al menos una aproximación cercana) a partir del conjunto de datos transformado. Esto es útil si queremos interpretar o visualizar los datos en su forma original después de reducir la dimensionalidad.\n",
        "\n",
        "En resumen, PCA es un algoritmo que reduce la dimensionalidad de un conjunto de datos al encontrar combinaciones lineales de las variables originales. Aunque intenta minimizar la pérdida de información, es importante tener en cuenta que existe una pérdida inherente al reducir las dimensiones. Sin embargo, PCA proporciona una herramienta útil para explorar y analizar conjuntos de datos complejos.\n",
        "\n",
        "\n",
        "\n",
        "Al entrenar el modelo PCA, aseguramos que se conserve la mayor cantidad posible de información del conjunto de datos original. Luego, podemos examinar los componentes resultantes y clasificarlos según su contribución al total de la información contenida en los datos. Esta contribución se representa mediante el concepto de \"porcentaje de varianza explicada acumulada\".\n",
        "\n",
        "El porcentaje de varianza explicada acumulada es una medida que indica el porcentaje de información que se conserva si utilizamos los 'n' componentes más importantes en lugar de todas las variables originales. En otras palabras, representa qué proporción de la variabilidad de los datos se captura al considerar solo los 'n' componentes más significativos.\n",
        "\n",
        "Al observar la curva de porcentaje de varianza explicada acumulada, podemos evaluar cómo se reduce la pérdida de información a medida que aumentamos el número de componentes considerados. Si seleccionamos un número suficiente de componentes con alta varianza explicada, podemos mantener una gran cantidad de información mientras reducimos la dimensionalidad del conjunto de datos.\n"
      ],
      "metadata": {
        "id": "q18_ZEcRWMS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.decomposition import PCA\n",
        "\n",
        "modelo_pca = PCA().fit(numericos)\n",
        "datos = numericos\n",
        "\n",
        "prop_varianza_acum = modelo_pca.explained_variance_ratio_.cumsum()\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "ax.plot(np.arange(len(datos.columns)),prop_varianza_acum,'-o')\n",
        "\n",
        "fig.set_figwidth(20)  \n",
        "ax.set_yticks([0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1])\n",
        "ax.set_title('Porcentaje de varianza explicada acumulada')\n",
        "ax.set_xlabel('Componente principal')\n",
        "ax.set_ylabel('Por. varianza acumulada')\n",
        "\n",
        "percentil90 = np.where(prop_varianza_acum >= 0.90)[0][0]\n",
        "print('90% de la información mantenida con ', percentil90, ' componentes')\n",
        "percentil95 = np.where(prop_varianza_acum >= 0.95)[0][0]\n",
        "print('95% de la información mantenida con ', percentil95, ' componentes')\n",
        "percentil99 = np.where(prop_varianza_acum >= 0.99)[0][0]\n",
        "print('99% de la información mantenida con ', percentil99, ' componentes')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 250
        },
        "id": "d4w4WG8pWOvm",
        "outputId": "a7473aea-329f-4458-9fee-204a910641a8"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "90% de la información mantenida con  6  componentes\n",
            "95% de la información mantenida con  8  componentes\n",
            "99% de la información mantenida con  16  componentes\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 2000x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se opta por coger la opción que mantiene un 95% de información, ya que elimina una buena parte de las columnas."
      ],
      "metadata": {
        "id": "JZrhGKUaGD75"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "modelo_pca = PCA(n_components=percentil95).fit(numericos)\n",
        "numericos = pd.DataFrame(modelo_pca.transform(numericos))\n",
        "numericos"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "qvyTRTY0WsY5",
        "outputId": "9f45b044-f249-43a7-a9f7-b52e3ab2ca30"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             0         1         2         3         4         5         6  \\\n",
              "0    -0.072166  0.379183  0.068896  0.029114 -0.004484 -0.017830  0.003112   \n",
              "1     0.035084 -0.022970  0.013141  0.048225  0.052215 -0.048207  0.005358   \n",
              "2     0.143608 -0.021087 -0.022895 -0.039265  0.058480 -0.053434  0.005990   \n",
              "3     0.033178 -0.021729  0.074926  0.010799  0.005100 -0.023178 -0.000815   \n",
              "4     0.034968 -0.022240 -0.077205 -0.020551  0.006991 -0.004363 -0.009689   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "7852  0.031392 -0.018923  0.038463 -0.071178  0.013041 -0.024029  0.000616   \n",
              "7853 -0.072164 -0.026681 -0.005693  0.147012 -0.011240  0.001725 -0.008492   \n",
              "7854  0.147889 -0.026529 -0.038883  0.058155 -0.001106 -0.005166 -0.011066   \n",
              "7855  0.034968 -0.022240 -0.077205 -0.020551  0.006991 -0.004363 -0.009689   \n",
              "7856  0.036898 -0.025150 -0.040594  0.061539 -0.001785 -0.002601 -0.009749   \n",
              "\n",
              "             7  \n",
              "0    -0.001593  \n",
              "1     0.023151  \n",
              "2     0.025135  \n",
              "3    -0.002052  \n",
              "4     0.012107  \n",
              "...        ...  \n",
              "7852  0.008865  \n",
              "7853 -0.005409  \n",
              "7854  0.002304  \n",
              "7855  0.012107  \n",
              "7856  0.003001  \n",
              "\n",
              "[7857 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-4ba12800-dfa6-440d-bf97-e15c2516d995\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-0.072166</td>\n",
              "      <td>0.379183</td>\n",
              "      <td>0.068896</td>\n",
              "      <td>0.029114</td>\n",
              "      <td>-0.004484</td>\n",
              "      <td>-0.017830</td>\n",
              "      <td>0.003112</td>\n",
              "      <td>-0.001593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.035084</td>\n",
              "      <td>-0.022970</td>\n",
              "      <td>0.013141</td>\n",
              "      <td>0.048225</td>\n",
              "      <td>0.052215</td>\n",
              "      <td>-0.048207</td>\n",
              "      <td>0.005358</td>\n",
              "      <td>0.023151</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.143608</td>\n",
              "      <td>-0.021087</td>\n",
              "      <td>-0.022895</td>\n",
              "      <td>-0.039265</td>\n",
              "      <td>0.058480</td>\n",
              "      <td>-0.053434</td>\n",
              "      <td>0.005990</td>\n",
              "      <td>0.025135</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.033178</td>\n",
              "      <td>-0.021729</td>\n",
              "      <td>0.074926</td>\n",
              "      <td>0.010799</td>\n",
              "      <td>0.005100</td>\n",
              "      <td>-0.023178</td>\n",
              "      <td>-0.000815</td>\n",
              "      <td>-0.002052</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.034968</td>\n",
              "      <td>-0.022240</td>\n",
              "      <td>-0.077205</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>0.006991</td>\n",
              "      <td>-0.004363</td>\n",
              "      <td>-0.009689</td>\n",
              "      <td>0.012107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7852</th>\n",
              "      <td>0.031392</td>\n",
              "      <td>-0.018923</td>\n",
              "      <td>0.038463</td>\n",
              "      <td>-0.071178</td>\n",
              "      <td>0.013041</td>\n",
              "      <td>-0.024029</td>\n",
              "      <td>0.000616</td>\n",
              "      <td>0.008865</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7853</th>\n",
              "      <td>-0.072164</td>\n",
              "      <td>-0.026681</td>\n",
              "      <td>-0.005693</td>\n",
              "      <td>0.147012</td>\n",
              "      <td>-0.011240</td>\n",
              "      <td>0.001725</td>\n",
              "      <td>-0.008492</td>\n",
              "      <td>-0.005409</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7854</th>\n",
              "      <td>0.147889</td>\n",
              "      <td>-0.026529</td>\n",
              "      <td>-0.038883</td>\n",
              "      <td>0.058155</td>\n",
              "      <td>-0.001106</td>\n",
              "      <td>-0.005166</td>\n",
              "      <td>-0.011066</td>\n",
              "      <td>0.002304</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7855</th>\n",
              "      <td>0.034968</td>\n",
              "      <td>-0.022240</td>\n",
              "      <td>-0.077205</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>0.006991</td>\n",
              "      <td>-0.004363</td>\n",
              "      <td>-0.009689</td>\n",
              "      <td>0.012107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7856</th>\n",
              "      <td>0.036898</td>\n",
              "      <td>-0.025150</td>\n",
              "      <td>-0.040594</td>\n",
              "      <td>0.061539</td>\n",
              "      <td>-0.001785</td>\n",
              "      <td>-0.002601</td>\n",
              "      <td>-0.009749</td>\n",
              "      <td>0.003001</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7857 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ba12800-dfa6-440d-bf97-e15c2516d995')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-4ba12800-dfa6-440d-bf97-e15c2516d995 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-4ba12800-dfa6-440d-bf97-e15c2516d995');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A partir de ahora, se realizará el tratamiento de las columnas categóricas directamente en train. Posteriormente se borraran las numércias que ya han sido tratadas a parte y se añadirán las columnas del DataSet **numericos** al final de train."
      ],
      "metadata": {
        "id": "CQvFE1tVX9Az"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A L0 y L2 se le aplica one hot, no hay orden posible."
      ],
      "metadata": {
        "id": "4E-C1SMpYKDT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "L0 = [i for i in range(1,42)]\n",
        "# L1 = np.arange(1,7)\n",
        "L2 = [i for i in range(1,11)]\n",
        "# L3 = np.arange(1,10)\n",
        "# L4 = L3.copy()\n",
        "\n",
        "# columnas_L3 = [str(i) for i in range(5,43,1)]\n",
        "# columnas_L4 = [str(i) for i in range(43,64,1)]\n",
        "\n",
        "X_train = aplicar_one_hot_encoding(X_train, '0', L0)\n",
        "# X_train = aplicar_one_hot_encoding(X_train, '3', L1)\n",
        "X_train = aplicar_one_hot_encoding(X_train, '4', L2)\n",
        "# for col in columnas_L3:\n",
        "#   X_train = aplicar_one_hot_encoding(X_train, col , L3)\n",
        "\n",
        "# for col in columnas_L4:\n",
        "#   X_train = aplicar_one_hot_encoding(X_train, col , L4)\n",
        "# X_train\n",
        "X_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "WuNqxHssX--G",
        "outputId": "1e6d62b1-7be1-4181-b329-a50c847f4159"
      },
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        1         2  3  5  6  7  8  9  10  11  ...  4_1  4_2  4_3  4_4  4_5  \\\n",
              "559   0.4  0.111111  4  0  3  0  6  5   0   4  ...    0    0    0    0    0   \n",
              "771   0.0  0.222222  3  9  0  0  0  6   2   2  ...    0    0    0    0    0   \n",
              "4701  0.0  0.333333  2  2  3  1  5  7   0   2  ...    0    0    1    0    0   \n",
              "3315  0.0  0.222222  3  0  4  1  5  6   2   2  ...    0    0    0    0    0   \n",
              "5133  0.0  0.222222  2  0  6  2  1  7   0   2  ...    0    0    1    0    0   \n",
              "...   ...       ... .. .. .. .. .. ..  ..  ..  ...  ...  ...  ...  ...  ...   \n",
              "57    0.0  0.222222  2  0  6  0  3  7   2   0  ...    0    0    1    0    0   \n",
              "578   0.0  0.111111  3  0  7  2  0  9   0   0  ...    0    0    0    0    0   \n",
              "26    0.0  0.333333  2  0  7  2  0  9   0   0  ...    0    0    1    0    0   \n",
              "2439  0.0  0.222222  3  1  6  2  2  7   1   2  ...    0    0    0    0    0   \n",
              "1366  0.0  0.222222  3  0  4  1  4  6   1   3  ...    0    1    0    0    0   \n",
              "\n",
              "      4_6  4_7  4_8  4_9  4_10  \n",
              "559     1    0    0    0     0  \n",
              "771     0    0    1    0     0  \n",
              "4701    0    0    0    0     0  \n",
              "3315    0    0    1    0     0  \n",
              "5133    0    0    0    0     0  \n",
              "...   ...  ...  ...  ...   ...  \n",
              "57      0    0    0    0     0  \n",
              "578     0    0    1    0     0  \n",
              "26      0    0    0    0     0  \n",
              "2439    0    0    0    1     0  \n",
              "1366    0    0    0    0     0  \n",
              "\n",
              "[7857 rows x 134 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-6bf4f163-596f-40a2-a933-1b34c2667b1b\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>4_1</th>\n",
              "      <th>4_2</th>\n",
              "      <th>4_3</th>\n",
              "      <th>4_4</th>\n",
              "      <th>4_5</th>\n",
              "      <th>4_6</th>\n",
              "      <th>4_7</th>\n",
              "      <th>4_8</th>\n",
              "      <th>4_9</th>\n",
              "      <th>4_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>5</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3315</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5133</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7857 rows × 134 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-6bf4f163-596f-40a2-a933-1b34c2667b1b')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-6bf4f163-596f-40a2-a933-1b34c2667b1b button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-6bf4f163-596f-40a2-a933-1b34c2667b1b');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "L1:\n",
        "\n",
        "    1 20-30 years\n",
        "    2 30-40 years\n",
        "    3 40-50 years\n",
        "    4 50-60 years\n",
        "    5 60-70 years\n",
        "    6 70-80 years\n",
        "\n",
        "L3:\n",
        "\n",
        "    0 0%\n",
        "    1 1 - 10%\n",
        "    2 11 - 23%\n",
        "    3 24 - 36%\n",
        "    4 37 - 49%\n",
        "    5 50 - 62%\n",
        "    6 63 - 75%\n",
        "    7 76 - 88%\n",
        "    8 89 - 99%\n",
        "    9 100%\n",
        "\n",
        "L4:\n",
        "\n",
        "    0 f 0\n",
        "    1 f 1 – 49\n",
        "    2 f 50 – 99\n",
        "    3 f 100 – 199\n",
        "    4 f 200 – 499\n",
        "    5 f 500 – 999\n",
        "    6 f 1000 – 4999\n",
        "    7 f 5000 – 9999\n",
        "    8 f 10.000 - 19.999\n",
        "    9 f 20.000 - ?\n"
      ],
      "metadata": {
        "id": "LYcgcT2MY3aH"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Estas tienen más interés, dado que parece que la variable categórica esta representando información en orden, siendo el más claro L1. En las demás, si bien se indica un cierto orden, es cierto que entre un valor y otro no se mantiene la proporcion (en los casos extremos). No obstante, se va a optar por tratarlas de la misma manera que L1.\n",
        "\n",
        "Estas columnas se dejarán tal cual dado que son categóricas ordinales y serán normalizadas según min max. Se podría hacer otra implementación de prueba apliando one hot a L3 y L4 pero por razones de tiempo se seguirá con esta idea.\n",
        "\n",
        "A continuación se hará una transformación min max para observar si dejando así la columna y normalizando, se sigue guardando la proporción."
      ],
      "metadata": {
        "id": "anCioOAiY7rs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "####Pruebas para L1\n",
        "\n",
        "p1 = np.array([1.0,2.0,3.0,4.0,5.0])\n",
        "\n",
        "for index, i in enumerate(p1):\n",
        "    p1[index] = (i-1)/(6 - 1)\n",
        "    p1[index] = p1[index] * (1 - 0) + 0\n",
        "\n",
        "print(p1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RaOK82ccZhuQ",
        "outputId": "f35b7feb-3ec2-411f-dc5d-d3d2ab412747"
      },
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[0.  0.2 0.4 0.6 0.8]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parece que no hay problema en normalizar ya que la proporcion se mantiene. Por tanto, se normalizan los grupos de columnas pertinentes."
      ],
      "metadata": {
        "id": "6Y9k90rSeCdd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "columnasL1 = ['3']\n",
        "columnasL3 = [str(i) for i in range(5,47,1)]\n",
        "columnasL4 = [str(i) for i in range(43,68,1)]\n",
        "\n",
        "X_train = aplicar_min_max_scaler(X_train, columnasL1, 6, 1)\n",
        "X_train = aplicar_min_max_scaler(X_train, columnasL3, 9, 0)\n",
        "X_train = aplicar_min_max_scaler(X_train, columnasL1, 9, 0)\n",
        "\n",
        "\n",
        "X_train\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "jPwQxtG7eKhN",
        "outputId": "f9f7d69c-a963-45ad-891e-31d2f731477b"
      },
      "execution_count": 119,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "        1         2         3         5         6         7         8  \\\n",
              "559   0.4  0.111111  0.066667  0.000000  0.333333  0.000000  0.666667   \n",
              "771   0.0  0.222222  0.044444  1.000000  0.000000  0.000000  0.000000   \n",
              "4701  0.0  0.333333  0.022222  0.222222  0.333333  0.111111  0.555556   \n",
              "3315  0.0  0.222222  0.044444  0.000000  0.444444  0.111111  0.555556   \n",
              "5133  0.0  0.222222  0.022222  0.000000  0.666667  0.222222  0.111111   \n",
              "...   ...       ...       ...       ...       ...       ...       ...   \n",
              "57    0.0  0.222222  0.022222  0.000000  0.666667  0.000000  0.333333   \n",
              "578   0.0  0.111111  0.044444  0.000000  0.777778  0.222222  0.000000   \n",
              "26    0.0  0.333333  0.022222  0.000000  0.777778  0.222222  0.000000   \n",
              "2439  0.0  0.222222  0.044444  0.111111  0.666667  0.222222  0.222222   \n",
              "1366  0.0  0.222222  0.044444  0.000000  0.444444  0.111111  0.444444   \n",
              "\n",
              "             9        10        11  ...  4_1  4_2  4_3  4_4  4_5  4_6  4_7  \\\n",
              "559   0.555556  0.000000  0.444444  ...    0    0    0    0    0    1    0   \n",
              "771   0.666667  0.222222  0.222222  ...    0    0    0    0    0    0    0   \n",
              "4701  0.777778  0.000000  0.222222  ...    0    0    1    0    0    0    0   \n",
              "3315  0.666667  0.222222  0.222222  ...    0    0    0    0    0    0    0   \n",
              "5133  0.777778  0.000000  0.222222  ...    0    0    1    0    0    0    0   \n",
              "...        ...       ...       ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
              "57    0.777778  0.222222  0.000000  ...    0    0    1    0    0    0    0   \n",
              "578   1.000000  0.000000  0.000000  ...    0    0    0    0    0    0    0   \n",
              "26    1.000000  0.000000  0.000000  ...    0    0    1    0    0    0    0   \n",
              "2439  0.777778  0.111111  0.222222  ...    0    0    0    0    0    0    0   \n",
              "1366  0.666667  0.111111  0.333333  ...    0    1    0    0    0    0    0   \n",
              "\n",
              "      4_8  4_9  4_10  \n",
              "559     0    0     0  \n",
              "771     1    0     0  \n",
              "4701    0    0     0  \n",
              "3315    1    0     0  \n",
              "5133    0    0     0  \n",
              "...   ...  ...   ...  \n",
              "57      0    0     0  \n",
              "578     1    0     0  \n",
              "26      0    0     0  \n",
              "2439    0    1     0  \n",
              "1366    0    0     0  \n",
              "\n",
              "[7857 rows x 134 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-0fdb16a6-0ac7-4c29-b6b9-29a455e240c7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>...</th>\n",
              "      <th>4_1</th>\n",
              "      <th>4_2</th>\n",
              "      <th>4_3</th>\n",
              "      <th>4_4</th>\n",
              "      <th>4_5</th>\n",
              "      <th>4_6</th>\n",
              "      <th>4_7</th>\n",
              "      <th>4_8</th>\n",
              "      <th>4_9</th>\n",
              "      <th>4_10</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>0.4</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>771</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4701</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3315</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5133</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>578</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2439</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1366</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>7857 rows × 134 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0fdb16a6-0ac7-4c29-b6b9-29a455e240c7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-0fdb16a6-0ac7-4c29-b6b9-29a455e240c7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-0fdb16a6-0ac7-4c29-b6b9-29a455e240c7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "A continuación, se une X_train con numericos tras eliminar las columnas numéricas originales de X_train."
      ],
      "metadata": {
        "id": "1HLROJ7Ce6cO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Lista de nombres de columnas a eliminar\n",
        "columnas_a_eliminar = ['1', '2']\n",
        "columnas_a_eliminar.extend([str(i) for i in range(64,85,1)])\n",
        "\n",
        "# Eliminar las columnas por su nombre\n",
        "X_train = X_train.drop(columns=columnas_a_eliminar)\n",
        "print(X_train.shape)\n",
        "\n",
        "X_train = X_train.to_numpy()\n",
        "numericos = numericos.to_numpy()\n",
        "X_train = pd.DataFrame(X_train)\n",
        "numericos = pd.DataFrame(numericos)\n",
        "\n",
        "X_train = pd.concat([X_train, numericos], axis=1)\n",
        "X_train = X_train.to_numpy()\n",
        "X_train = pd.DataFrame(X_train)\n",
        "X_train\n",
        "print(X_train.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e-A5FLOgfFJm",
        "outputId": "71625d05-bde9-4669-df02-91a1550b16c7"
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7857, 111)\n",
            "(7857, 119)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ahora sería el momento de los outliers y de recalcular los indices de validación. LocalOutlierFactor (LOF) es un algoritmo de detección de anomalías utilizado en aprendizaje automático. Su objetivo principal es identificar puntos de datos atípicos o \"anómalos\" en un conjunto de datos. LOF se basa en la suposición de que los puntos anómalos tienen una densidad de vecinos significativamente menor en comparación con los puntos normales en su vecindario local."
      ],
      "metadata": {
        "id": "KCRjOYBTqYHk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ###OUTLIERS\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "# # identify outliers in the training dataset\n",
        "datos_antes = X_train.shape[0]\n",
        "\n",
        "X_train_p = X_train.to_numpy()\n",
        "y_train_p = y_train.to_numpy()\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "yhat = lof.fit_predict(X_train_p)\n",
        "mask = yhat != -1\n",
        "X_train_p, y_train_p = X_train_p[mask, :], y_train_p[mask]\n",
        "\n",
        "X_train_p = pd.DataFrame(X_train_p)\n",
        "y_train_p = pd.DataFrame(y_train_p)\n",
        "\n",
        "datos_despues = X_train_p.shape[0]\n",
        "print(X_train.shape)\n",
        "print(\"Datos eliminados por LOF: \", (datos_antes-datos_despues)/datos_antes*100, \"%\")\n",
        "# ##Se repite CV-5\n",
        "#5-fold cross validation\n",
        "# particiones = np.empty((5),list)\n",
        "\n",
        "# train_data = X_train.to_numpy()\n",
        "# train_labels = y_train.to_numpy()\n",
        "\n",
        "# index_train = np.arange(len(train_labels))\n",
        "\n",
        "# for i in range(5):\n",
        "#   particiones[i] = []\n",
        "\n",
        "# #En vez de tener varios conjuntos de datos, usaremos conjuntos de índices, que son mucho más cómodos de manejar\n",
        "# for i in range(index_train.shape[0]):\n",
        "#   particiones[i%5].append(index_train[i])\n",
        "  \n",
        "# for i in range(5):\n",
        "#   particiones[i] = np.asarray(particiones[i])\n",
        "#   np.random.shuffle(particiones[i])\n",
        "\n",
        "# training1 = np.concatenate((particiones[0],particiones[1],particiones[2],particiones[3]))\n",
        "# test1 = particiones[4]\n",
        "\n",
        "# training2 = np.concatenate((particiones[4],particiones[0],particiones[1],particiones[2]))\n",
        "# test2 = particiones[3]\n",
        "\n",
        "# training3 = np.concatenate((particiones[3],particiones[4],particiones[0],particiones[1]))\n",
        "# test3 = particiones[2]\n",
        "\n",
        "# training4 = np.concatenate((particiones[2],particiones[3],particiones[4],particiones[0]))\n",
        "# test4 = particiones[1]\n",
        "\n",
        "# training5 = np.concatenate((particiones[1],particiones[2],particiones[3],particiones[4]))\n",
        "# test5 = particiones[0]\n",
        "\n",
        "# cv_trains = [training1,training2,training3,training4,training5]\n",
        "# cv_tests = [test1,test2,test3,test4,test5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nqaKIeAzM3hI",
        "outputId": "801c66bd-f987-4e5a-aebe-eadfe9f14bf2"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(7857, 119)\n",
            "Datos eliminados por LOF:  10.003818251240931 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, la técnica LOF elimina demasiados datos del dataset (en torno al 10%), lo cual es drástico partiendo de que el DataSet no tiene una exageración de entradas. Dada la diemensionalidad de este, sería crítico observar una a una las diferentes entradas para detectar algún dato anómalo u erróneo, así que se dejará como está."
      ],
      "metadata": {
        "id": "ppQ6jOxaHv7Y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este apartado final es a modo de explicación. Al principio, en vez de hacer PCA a las numéricas y unir después con las categóricas transformadas, se pensaba hacer FAMD, una técnica parecida a PCA (en cuanto a lo que pretende conseguir), pero pensada para DataSets mixtos (con información numérica y categórica). No obstante, dadas las pocas referencias teóricas que se tenían sobre este método y a la dificultad para entender los parámetros de la biblioteca prince, se optó por lo que se ha hecho, aunque sería una buena idea rehacerlo todo aplicando esta técnica y ver que tal los resultados."
      ],
      "metadata": {
        "id": "dWB6OF95qbuy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# # !pip install pprint\n",
        "# import prince\n",
        "# import pprint\n",
        "\n",
        "\n",
        "# # (1,2 y de la 64 a la 84).\n",
        "# for col in X_train.columns:\n",
        "#   if(col == 1 or col == 2 or col in np.arange(64,85)):\n",
        "#     pass\n",
        "#   else:\n",
        "#     X_train[col] = X_train[col].astype(\"category\")\n",
        "\n",
        "# # X_train2 = X_train.select_dtypes(np.number).columns\n",
        "# # X_train2\n",
        "# # Crea un diccionario para mapear los títulos de columna actuales\n",
        "# # a cadenas de texto (str)\n",
        "# nuevos_titulos = {col: str(col) for col in X_train.columns}\n",
        "# print(nuevos_titulos)\n",
        "# # Utiliza la función \"rename()\" para cambiar los títulos de columna\n",
        "# X_train = X_train.rename(columns=nuevos_titulos)\n",
        "# # Instantiate FAMD object\n",
        "# famd = prince.FAMD(\n",
        "#      n_components=25,\n",
        "#      n_iter=10,\n",
        "#      copy=True,\n",
        "#      check_input=True,\n",
        "#      engine='sklearn',       ## Can be \"auto\", 'sklearn', 'fbpca'\n",
        "#      random_state=33)\n",
        "\n",
        "# ## Fit FAMD object to data \n",
        "# famd = famd.fit(X_train) \n",
        "\n",
        "# ## Inspect principal dimensions\n",
        "# pp = pprint.PrettyPrinter()\n",
        "# pp.pprint(famd) \n",
        "# X_train"
      ],
      "metadata": {
        "id": "xyxBUCiiueNY"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### <font color='blue'>5)  Justifique las métricas de error y la función de pérdida a usar. Discutir su idoneidad para el problema. 0.5 puntos. "
      ],
      "metadata": {
        "id": "3QXdZX5DgM0c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Dado que estamos abordando un problema de clasificación binaria y nuestro objetivo es maximizar la proporción de datos clasificados correctamente, utilizaremos la métrica de precisión (Accuracy) como medida de evaluación. Accuracy se define como la proporción de predicciones correctas sobre el total de predicciones realizadas.\n",
        "\n",
        "En lugar de implementar nuestra propia métrica de precisión, podemos aprovechar la comodidad que nos brinda la biblioteca scikit-learn (sklearn) en Python. Sklearn proporciona una implementación precisa y fácil de usar de varias métricas de evaluación, incluida la métrica Accuracy."
      ],
      "metadata": {
        "id": "lyG7EATwW-la"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Matriz de confusión\n",
        "\n",
        "Es cierto que en problemas de clasificación desbalanceados, donde una clase tiene una representación mucho mayor que la otra, el uso exclusivo de la métrica Accuracy puede ser engañoso. Como se mencionó, un clasificador que siempre predice la clase mayoritaria podría tener una alta precisión simplemente por \"adivinar\" la clase mayoritaria en la mayoría de los casos.\n",
        "\n",
        "Para abordar esta situación, una buena práctica es utilizar la matriz de confusión (confusion matrix) al evaluar nuestro clasificador. La matriz de confusión es una herramienta que resume las clasificaciones realizadas por un modelo, mostrando la cantidad de ejemplos que fueron clasificados correctamente y los que fueron clasificados incorrectamente para cada clase.\n",
        "\n",
        "La matriz de confusión nos permite identificar rápidamente los resultados anómalos o indeseables en términos de clasificaciones incorrectas. A partir de esta matriz, podemos extraer diversas métricas que nos brindan información más detallada sobre el rendimiento del clasificador."
      ],
      "metadata": {
        "id": "tOJmIGiJXJEl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso, al enfrentarnos a un desbalanceo de clases, nos interesará evaluar dos medidas específicas: Sensitivity (sensibilidad) y Specificity (especificidad). Estas medidas nos ayudarán a comprender cómo nuestro modelo está clasificando correctamente los positivos ('1') y los negativos ('0') respectivamente.\n",
        "\n",
        "+ La Sensitivity se refiere al porcentaje de ejemplos positivos ('1') que han sido correctamente clasificados por nuestro modelo. Es decir, representa la capacidad del modelo para identificar correctamente los verdaderos positivos. \n",
        "\n",
        "+ La Specificity representa el porcentaje de ejemplos negativos ('0') que han sido correctamente clasificados, lo que refleja la capacidad del modelo para identificar los verdaderos negativos.\n",
        "\n",
        "La matriz de confusión, que podemos obtener fácilmente utilizando la función proporcionada por sklearn, es una herramienta valiosa para calcular estas medidas. La matriz de confusión resume las clasificaciones realizadas por el modelo en cuatro categorías: verdaderos positivos (TP), falsos positivos (FP), verdaderos negativos (TN) y falsos negativos (FN)."
      ],
      "metadata": {
        "id": "KiouCDwAX1wC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Todo esto tiene como fin, usar el balanced accuracy para comparar modelos. Justamente la fórmula para calcularlo es la siguiente:\n",
        "\n",
        "$Balanced\\ Accuracy = \\frac{Sensitivity + Specificity}{2}$\n",
        "\n",
        "Es una métrica que nos viene muy bien para nuestro DataSet desbalanceado, ya que otorga la misma importancia a acertar positivos o negativos.\n",
        "\n",
        "Además de todo esto, en los distintos algoritmos se explorará el parámetro class_weight. muy útil también para clases desbalanceadas."
      ],
      "metadata": {
        "id": "KjtVo2amYbE7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Función de pérdida\n",
        "\n",
        "En cuanto a la función de pérdida, Regresión Logística hace uso de la Entropía Cruzada y Perceptron realmente no tiene una función de pérdida como tal si no que en cada iteración intenta clasificar bien un punto mal clasificado en base a su distancia a la recta actual."
      ],
      "metadata": {
        "id": "EnzUUuFuP9mX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import metrics\n",
        "def puntuar(sensitivity, specificity):\n",
        "  return (sensitivity+specificity)/2"
      ],
      "metadata": {
        "id": "lJOzrzg9g56_"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>6)  Discuta todos los parámetros y el tipo de regularización usada en el ajuste de los modelos seleccionados. Justificar la idoneidad de la regularización elegida. 1 punto. "
      ],
      "metadata": {
        "id": "S4Lo3fC0g6Cv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Usaré dos modelos de aprendizaje: PLA+Pocket y Regresión Logística. Para PLA+Pocket, a pesar de que sklearn no tiene una implementación directa de Pocket, podemos lograr algo similar utilizando PLA con Early Stopping. Para Regresión Logística, utilizaré tanto la implementación directa de sklearn 'LogisticRegression', como 'SGDClassifier' con el parámetro loss='log_loss' para poder usar el algoritmo SGD. Compararé ambos modelos y seleccionaré el que me dé mejores resultados.\n",
        "\n",
        "Para seleccionar los hiperparámetros, los elegiré mediante teoría o mediante Gridsearch. Sin embargo, realizar Gridsearch con todos los posibles hiperparámetros es computacionalmente inviable debido al crecimiento exponencial del número de modelos que se deben entrenar. Por lo tanto, consideraré otras opciones, como elegir algunos parámetros antes del Gridsearch basándome en una pequeña batería experimental, o seleccionar parámetros después del Gridsearch para maximizar los resultados o cuando haya demasiadas opciones para probar.\n",
        "\n",
        "Es importante tener en cuenta que los resultados pueden variar ligeramente entre ejecuciones debido a la aleatoriedad y a la proximidad de los resultados entre sí. A continuación, enumeraré los hiperparámetros relevantes, los valores seleccionados y las justificaciones para cada modelo de aprendizaje."
      ],
      "metadata": {
        "id": "xnzqZSUBajlE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "REGRESIÓN LOGÍSTICA"
      ],
      "metadata": {
        "id": "hINB1BG3bEES"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de realizar cualquier ejecución, hay ciertos hiperparámetros que prefijaré. \n",
        "\n",
        "+ En primer lugar, elijo el algoritmo de optimización 'solver' para los modelos de Regresión Logística. Basándome en la documentación oficial de sklearn (https://scikit-learn.org/dev/modules/linear_model.html#logistic-regression), elijo 'Saga' o 'Sas' debido al tamaño grande de nuestro conjunto de datos. Saga es preferido, ya que es similar a Sas pero soporta todos los tipos de regularización. \n",
        "\n",
        "*The “sag” solver uses Stochastic Average Gradient descent. It is faster than other solvers for large datasets, when both the number of samples and the number of features are large.*\n",
        "\n",
        "*The “saga” solver is a variant of “sag” that also supports the non-smooth penalty=\"l1\". This is therefore the solver of choice for sparse multinomial logistic regression. It is also the only solver that supports penalty=\"elasticnet\".*\n",
        "\n",
        "+ El parámetro 'warm_start' no tendrá un impacto significativo en nuestro caso, ya que solo entrenamos el modelo una vez, por lo que lo dejaremos en su valor predeterminado (False).\n",
        "\n",
        "+ Dado que tenemos una clasificación binaria, la estrategia de clasificación 'multi_class' será seleccionada automáticamente como 'ovr' (One-vs-Rest) por defecto, lo cual es apropiado en este escenario.\n",
        "\n",
        "+ En cuanto al parámetro 'n_jobs', estableceré su valor en -1 para aprovechar todos los núcleos de la CPU disponibles, aunque en una clasificación binaria no proporcionará una mejora significativa en el rendimiento.\n",
        "\n",
        "+ El parámetro 'dual' se mantendrá en su valor predeterminado (False) porque no se recomienda utilizar la formulación dual cuando el número de muestras es mayor que el número de atributos, como es nuestro caso.\n",
        "\n",
        "+ Los hiperparámetros 'random_state', 'intercept_scaling' y 'verbose' se dejarán en sus valores predeterminados debido a que no son relevantes en nuestro contexto.\n",
        "\n",
        "+ El hiperparámetro 'l1_ratio' no será utilizado, ya que no estamos interesados en utilizar la regularización 'Elastic-Net', y su valor se establecerá en su valor predeterminado (None).\n",
        "\n",
        "+ Por último, mantendremos el valor predeterminado de 'fit_intercept' en True, ya que agregar una constante a la función de decisión suele ser una buena práctica.\n",
        "\n",
        "Para algunos hiperparámetros, realizaré una exploración experimental antes de utilizar Gridsearch. \n",
        "\n",
        "+ Estos incluyen 'tol' (tolerancia del criterio de parada) y 'max_iter' (número máximo de iteraciones permitidas para converger).\n",
        "\n",
        "Luego, utilizaré Gridsearch para explorar diferentes valores de los hiperparámetros:\n",
        "+ 'penalty' (tipo de regularización) \n",
        "+ 'C' (inversa del factor de regularización). \n",
        "\n",
        "Para el tipo de regularización, solo consideraré 'l1' y 'l2', ya que 'elasticnet' es más complejo y escapa al alcance de esta práctica.\n",
        "\n",
        "Después de Gridsearch, exploraré el hiperparámetro 'class_weight' para abordar el desequilibrio de clases en nuestro conjunto de datos. Al asignar diferentes pesos a las clases, intentaré maximizar la precisión para ambas clases, especialmente para la clase '1' que está desbalanceada."
      ],
      "metadata": {
        "id": "7srEBN0RbFq6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression"
      ],
      "metadata": {
        "id": "UMFXvWkO1Ivf"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "SGD CLASIFFIER"
      ],
      "metadata": {
        "id": "Ciu3EgtnPXzG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Antes de ejecutar el algoritmo SGD, se establecen ciertos parámetros que afectan su funcionamiento:\n",
        "\n",
        "+ Función de pérdida (loss): Es la función utilizada para medir la discrepancia entre las predicciones y los valores reales. En este caso, se utiliza la función logarítmica para clasificación logística.\n",
        "\n",
        "+ Warm_start: Es una técnica que consiste en reutilizar la solución anterior como punto de partida para el entrenamiento actual. En este caso, como solo se entrena el modelo una vez, no es relevante.\n",
        "\n",
        "+ n_jobs: Indica el número de núcleos de CPU utilizados para ejecutar en paralelo. Un valor de -1 significa utilizar todos los núcleos disponibles, aunque en problemas de clasificación binaria puede tener un impacto limitado en el rendimiento.\n",
        "\n",
        "+ shuffle: Determina si se deben reordenar los datos después de cada iteración. En general, es recomendable reordenarlos, y por defecto se establece en True.\n",
        "\n",
        "+ random_state: Se utiliza cuando shuffle es True para establecer la semilla aleatoria para el reordenamiento de los datos. En este caso, se utiliza el valor predeterminado (None) para generar aleatoriamente la semilla.\n",
        "\n",
        "+ verbose: Controla la cantidad de información que se muestra durante la ejecución. El valor predeterminado de 0 indica que se muestra la mínima información necesaria.\n",
        "\n",
        "+ epsilon: Se utiliza en funciones de pérdida epsilon-insensibles, pero no es relevante para este caso.\n",
        "\n",
        "+ l1_ratio: Se aplica cuando se utiliza la regularización \"Elastic-Net\" y determina cómo se mezclan las penalizaciones L1 y L2. No se utiliza en este caso, por lo que se mantiene el valor predeterminado.\n",
        "\n",
        "+ fit_intercept: Indica si se debe agregar una constante a la función de decisión. Es una práctica común y se establece en True por defecto.\n",
        "\n",
        "+ early_stopping: Se utiliza para detener el entrenamiento antes de tiempo si no se observa una mejora en la solución basada en un conjunto de validación. No se utiliza en este caso.\n",
        "\n",
        "+ validation_fraction: Determina el porcentaje de datos que se utilizará para la validación cuando se utiliza early_stopping. No es relevante en este caso.\n",
        "\n",
        "+ average: Indica si se debe calcular y almacenar el promedio de los pesos de todas las actualizaciones. No se utiliza en este estudio.\n",
        "\n",
        "Además, se establecerán experimentalmente los siguientes hiperparámetros antes de Gridsearch:\n",
        "\n",
        "+ tol: Es la tolerancia que determina cuándo se considera que la solución no ha empeorado lo suficiente.\n",
        "\n",
        "+ n_iter_no_change: Es el número de iteraciones consecutivas en las que la solución no mejora antes de detener el entrenamiento.\n",
        "\n",
        "+ max_iter: Es el número máximo de épocas (iteraciones) permitidas.\n",
        "\n",
        "Después de establecer los parámetros mencionados anteriormente, se realizará una búsqueda en la cuadrícula (Gridsearch) para encontrar los mejores hiperparámetros. Los hiperparámetros que se explorarán son los siguientes:\n",
        "\n",
        "+ Penalty: Es el tipo de regularización que se aplicará. Se considerarán dos opciones: 'l1' y 'l2'. No se utilizará 'elasticnet' en este estudio.\n",
        "\n",
        "+ alpha: Es el factor de regularización que controla la intensidad de la regularización. Se probarán tres valores: 1 (valor predeterminado), 1000 (regularización alta) y 0.001 (regularización baja). Estos valores permitirán evaluar el impacto de diferentes niveles de regularización en el modelo.\n",
        "\n",
        "+ Learning Rate: Se explorará utilizando dos enfoques diferentes:\n",
        "\n",
        "    a) Constante (constant): Se utilizará un valor constante de Learning Rate para el entrenamiento. Se probarán diferentes valores de eta0 (0.0001, 1 y 1000) para evaluar su impacto en el rendimiento del modelo. Si se observa una mejora significativa con algún valor, se puede realizar una exploración más detallada dentro de ese rango.\n",
        "\n",
        "    b) Óptimo (optimal): Se utilizará el Learning Rate óptimo, que es adaptativo y varía durante el entrenamiento para lograr una convergencia más rápida. Se explorarán diferentes combinaciones de tipos y valores de Learning Rate para buscar el mejor resultado posible.\n",
        "\n",
        "+ eta0: Se aplica solo cuando se utiliza el enfoque de Learning Rate constante. Representa el valor constante del Learning Rate. Se probarán valores de eta0 de 0.0001, 1 y 1000 para evaluar su impacto en el rendimiento.\n",
        "\n",
        "Después de Gridsearch, se realizarán experimentos con los siguientes hiperparámetros:\n",
        "\n",
        "+ class_weight - Pesos asociados a las clases de nuestro modelo. Como en nuestro caso tenemos muchísimo desbalance, es muy probable que el algoritmo prácticamente desprecie la clase 'yes', por lo que intentaré darle diferentes pesos a las clases, en busca de maximizar el acierto sobre esa clase también.\n",
        "\n",
        "+ Learning Rate, así como sus parámetros asociados (eta0 y power_t)"
      ],
      "metadata": {
        "id": "ZXIVcvLcPcKB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import SGDClassifier"
      ],
      "metadata": {
        "id": "TWz5jPyHg77H"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "PERCEPTRON POCKET"
      ],
      "metadata": {
        "id": "3FOVI-ldRDAM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es cierto que el algoritmo Perceptron (PLA) está diseñado para iterar hasta que pueda separar perfectamente el conjunto de datos. Sin embargo, cuando el conjunto de datos no es linealmente separable, el PLA puede continuar iterando indefinidamente sin lograr una separación adecuada.\n",
        "\n",
        "Una solución sencilla para este problema sería limitar el número de iteraciones. Sin embargo, esto plantea dos problemas importantes. En primer lugar, no garantiza detenerse después de converger, lo que significa que podría terminar antes de encontrar una solución óptima. En segundo lugar, no garantiza devolver la mejor solución encontrada, ya que podría detenerse antes de alcanzar una solución óptima.\n",
        "\n",
        "Para abordar estos problemas, se puede utilizar una técnica llamada Early Stopping (detención temprana). En lugar de detenerse después de un número fijo de iteraciones, el algoritmo se detiene cuando no logra mejorar los resultados. Esto se logra reservando una fracción de los datos para validación y monitoreando el rendimiento del modelo en estos datos de validación.\n",
        "\n",
        "Al utilizar Early Stopping, podemos simular algo similar al Pocket-PLA. En lugar de detenerse después de un número fijo de ejecuciones, el algoritmo se detendrá cuando se determine que no puede mejorar los resultados utilizando los datos de validación. Esto nos permite obtener una solución que no solo convergio, sino que también es la mejor posible en términos de los datos de validación."
      ],
      "metadata": {
        "id": "Be2iYt1uSHDn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Vamos a repasar los parámetros que vamos a establecer antes de ejecutar cualquier proceso:\n",
        "\n",
        "+ Warm_start: Esta técnica consiste en reutilizar la solución del entrenamiento anterior como inicialización para el siguiente entrenamiento. En nuestro caso, como solo entrenamos una vez por modelo, su valor predeterminado (False) es indiferente.\n",
        "\n",
        "+ n_jobs: Determina el número de núcleos de la CPU que se utilizarán para paralelizar la ejecución. Establecerlo en -1 permite utilizar todos los núcleos disponibles. Aunque en un problema de clasificación binaria no mejora significativamente el rendimiento, no tiene efectos negativos.\n",
        "\n",
        "+ shuffle: Indica si los datos deben ser reordenados después de cada época. Es una buena práctica realizar esta reordenación, por lo que se mantiene el valor predeterminado (True).\n",
        "\n",
        "+ random_state: Si shuffle es True, este parámetro determina la semilla utilizada para la reordenación. Se puede especificar un entero, una instancia de 'randomState' o dejarlo en None para generar una semilla aleatoria. En nuestro caso, la semilla no es relevante, por lo que se mantiene el valor predeterminado (None).\n",
        "\n",
        "+ verbose: Controla la cantidad de información del registro que se muestra por pantalla. Al ser una variable informativa, se mantiene en su valor predeterminado (0).\n",
        "\n",
        "+ l1_ratio: Este parámetro se utiliza en la regularización 'Elastic-Net' para mezclar las penalizaciones L1 y L2. No vamos a utilizar esta regularización en nuestra práctica, por lo que se mantiene en su valor predeterminado (0.15).\n",
        "\n",
        "+ fit_intercept: Indica si se permite añadir una constante a la función de decisión. En la mayoría de los casos, es una buena práctica incluir esta constante, ya que proporciona más flexibilidad al algoritmo. Por lo tanto, se mantiene en su valor predeterminado (True).\n",
        "\n",
        "+ early_stopping: Si se activa, se reservará una fracción de los datos para validación y el algoritmo se detendrá cuando no se observe mejora en los resultados de validación. En el caso del Perceptron, esto nos permite simular una versión similar al Pocket-PLA. Por lo tanto, se establece en True.\n",
        "\n",
        "+ validation_fraction: Determina el porcentaje de datos que se utilizarán para validación si se utiliza early_stopping. Como no vamos a utilizarlo, su valor predeterminado no es relevante.\n",
        "\n",
        "A continuación, detallamos los parámetros que vamos a ajustar experimentalmente antes de realizar la búsqueda en cuadrícula (Gridsearch):\n",
        "\n",
        "+ tol: Tolerancia que indica cuándo se considera que la solución no ha mejorado.\n",
        "\n",
        "+ n_iter_no_change: Número de iteraciones consecutivas en las que la solución no mejora antes de detener el entrenamiento.\n",
        "\n",
        "+ max_iter: Número máximo de épocas permitidas.\n",
        "\n",
        "Estos tres parámetros son fundamentales para el criterio de parada. Buscaremos valores que sean consistentes en todos los modelos y permitan la convergencia.\n",
        "\n",
        "Ahora, pasamos a los parámetros que ajustaremos experimentalmente mediante Gridsearch:\n",
        "\n",
        "+ Penalty: Este parámetro determina el tipo de regularización. Existen varios tipos, pero en nuestra práctica nos limitaremos a 'l1' y 'l2'. Explorar diferentes valores de 'l1_ratio', incluyendo 0 para 'l2' y 1 para 'l1', sería una opción interesante, pero se escapa del alcance de nuestros conocimientos teóricos actuales.\n",
        "\n",
        "+ alpha: Es el factor de regularización, que determina la fuerza de la regularización. Valores más altos indican una regularización más fuerte. Vamos a probar tres valores: 1 (valor predeterminado), 1000 (regularización muy alta) y 0.001 (regularización muy baja). Si observamos diferencias significativas con alguno de estos valores, podremos explorar valores intermedios después de la búsqueda en cuadrícula.\n",
        "\n",
        "+ eta0: Learning Rate (tasa de aprendizaje) en el Perceptron. En nuestro caso, solo puede ser constante. Vamos a probar tres valores: 0.0001, 1 y 1000. Si encontramos una mejora sustancial con alguno de ellos, podemos investigar más a fondo ese rango de valores.\n",
        "\n",
        "Por último, mencionamos los parámetros que ajustaremos experimentalmente después de la búsqueda en cuadrícula:\n",
        "\n",
        "+ class_weight: Estos pesos se asocian a las clases del modelo. Dado que tenemos un gran desequilibrio de clases, es probable que el algoritmo ignore prácticamente la clase 'yes'. Intentaremos asignar diferentes pesos a las clases para maximizar la precisión en ambas."
      ],
      "metadata": {
        "id": "kUYOygbGRfAJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import Perceptron"
      ],
      "metadata": {
        "id": "FNl08aDQOX3v"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "aux_train_data = X_train[:int(X_train.shape[0]*0.1)]\n",
        "aux_train_labels = y_train[:int(X_train.shape[0]*0.1)]\n",
        "aux_test_data = X_train[-int(X_train.shape[0]*0.1):-1]\n",
        "aux_test_labels = y_train[-int(X_train.shape[0]*0.1):-1]"
      ],
      "metadata": {
        "id": "6vD-FF-LxL3T"
      },
      "execution_count": 127,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOGISTIC REGRESSION"
      ],
      "metadata": {
        "id": "wC6iiJGZLE_y"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAX ITER"
      ],
      "metadata": {
        "id": "wU7M7eieLRvG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = LogisticRegression(max_iter=10000, solver='saga', n_jobs=-1).fit(aux_train_data,aux_train_labels)\n",
        "print(w.n_iter_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYAxWcJQLTKS",
        "outputId": "bb927cd7-ba21-4312-f73a-13f4ef846364"
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[741]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iter1 = 100\n",
        "# Obtener el máximo y mínimo de cada columna\n",
        "for columna in X_train.columns:\n",
        "    valor_maximo = X_train[columna].max()\n",
        "    valor_minimo = X_train[columna].min()\n",
        "    print(f'Máximo de {columna}: {valor_maximo}')\n",
        "    print(f'Mínimo de {columna}: {valor_minimo}')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1c80tiFsdCKO",
        "outputId": "264cbc01-a05a-484d-b62b-3773b6dd1a78"
      },
      "execution_count": 129,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Máximo de 0: 0.1111111111111111\n",
            "Mínimo de 0: 0.0\n",
            "Máximo de 1: 1.0\n",
            "Mínimo de 1: 0.0\n",
            "Máximo de 2: 1.0\n",
            "Mínimo de 2: 0.0\n",
            "Máximo de 3: 0.5555555555555556\n",
            "Mínimo de 3: 0.0\n",
            "Máximo de 4: 1.0\n",
            "Mínimo de 4: 0.0\n",
            "Máximo de 5: 1.0\n",
            "Mínimo de 5: 0.0\n",
            "Máximo de 6: 0.7777777777777778\n",
            "Mínimo de 6: 0.0\n",
            "Máximo de 7: 1.0\n",
            "Mínimo de 7: 0.0\n",
            "Máximo de 8: 1.0\n",
            "Mínimo de 8: 0.0\n",
            "Máximo de 9: 1.0\n",
            "Mínimo de 9: 0.0\n",
            "Máximo de 10: 1.0\n",
            "Mínimo de 10: 0.0\n",
            "Máximo de 11: 1.0\n",
            "Mínimo de 11: 0.0\n",
            "Máximo de 12: 1.0\n",
            "Mínimo de 12: 0.0\n",
            "Máximo de 13: 1.0\n",
            "Mínimo de 13: 0.0\n",
            "Máximo de 14: 1.0\n",
            "Mínimo de 14: 0.0\n",
            "Máximo de 15: 0.5555555555555556\n",
            "Mínimo de 15: 0.0\n",
            "Máximo de 16: 1.0\n",
            "Mínimo de 16: 0.0\n",
            "Máximo de 17: 1.0\n",
            "Mínimo de 17: 0.0\n",
            "Máximo de 18: 1.0\n",
            "Mínimo de 18: 0.0\n",
            "Máximo de 19: 1.0\n",
            "Mínimo de 19: 0.0\n",
            "Máximo de 20: 1.0\n",
            "Mínimo de 20: 0.0\n",
            "Máximo de 21: 1.0\n",
            "Mínimo de 21: 0.0\n",
            "Máximo de 22: 1.0\n",
            "Mínimo de 22: 0.0\n",
            "Máximo de 23: 1.0\n",
            "Mínimo de 23: 0.0\n",
            "Máximo de 24: 1.0\n",
            "Mínimo de 24: 0.0\n",
            "Máximo de 25: 1.0\n",
            "Mínimo de 25: 0.0\n",
            "Máximo de 26: 1.0\n",
            "Mínimo de 26: 0.0\n",
            "Máximo de 27: 1.0\n",
            "Mínimo de 27: 0.0\n",
            "Máximo de 28: 1.0\n",
            "Mínimo de 28: 0.0\n",
            "Máximo de 29: 1.0\n",
            "Mínimo de 29: 0.0\n",
            "Máximo de 30: 1.0\n",
            "Mínimo de 30: 0.0\n",
            "Máximo de 31: 1.0\n",
            "Mínimo de 31: 0.0\n",
            "Máximo de 32: 1.0\n",
            "Mínimo de 32: 0.0\n",
            "Máximo de 33: 1.0\n",
            "Mínimo de 33: 0.0\n",
            "Máximo de 34: 1.0\n",
            "Mínimo de 34: 0.0\n",
            "Máximo de 35: 1.0\n",
            "Mínimo de 35: 0.0\n",
            "Máximo de 36: 0.7777777777777778\n",
            "Mínimo de 36: 0.0\n",
            "Máximo de 37: 1.0\n",
            "Mínimo de 37: 0.0\n",
            "Máximo de 38: 0.8888888888888888\n",
            "Mínimo de 38: 0.1111111111111111\n",
            "Máximo de 39: 0.3333333333333333\n",
            "Mínimo de 39: 0.0\n",
            "Máximo de 40: 0.6666666666666666\n",
            "Mínimo de 40: 0.0\n",
            "Máximo de 41: 0.4444444444444444\n",
            "Mínimo de 41: 0.0\n",
            "Máximo de 42: 1.0\n",
            "Mínimo de 42: 0.0\n",
            "Máximo de 43: 7.0\n",
            "Mínimo de 43: 0.0\n",
            "Máximo de 44: 7.0\n",
            "Mínimo de 44: 0.0\n",
            "Máximo de 45: 9.0\n",
            "Mínimo de 45: 0.0\n",
            "Máximo de 46: 5.0\n",
            "Mínimo de 46: 0.0\n",
            "Máximo de 47: 7.0\n",
            "Mínimo de 47: 0.0\n",
            "Máximo de 48: 6.0\n",
            "Mínimo de 48: 0.0\n",
            "Máximo de 49: 6.0\n",
            "Mínimo de 49: 0.0\n",
            "Máximo de 50: 8.0\n",
            "Mínimo de 50: 0.0\n",
            "Máximo de 51: 6.0\n",
            "Mínimo de 51: 0.0\n",
            "Máximo de 52: 3.0\n",
            "Mínimo de 52: 0.0\n",
            "Máximo de 53: 7.0\n",
            "Mínimo de 53: 0.0\n",
            "Máximo de 54: 8.0\n",
            "Mínimo de 54: 0.0\n",
            "Máximo de 55: 3.0\n",
            "Mínimo de 55: 0.0\n",
            "Máximo de 56: 6.0\n",
            "Mínimo de 56: 0.0\n",
            "Máximo de 57: 1.0\n",
            "Mínimo de 57: 0.0\n",
            "Máximo de 58: 6.0\n",
            "Mínimo de 58: 0.0\n",
            "Máximo de 59: 5.0\n",
            "Mínimo de 59: 0.0\n",
            "Máximo de 60: 1.0\n",
            "Mínimo de 60: 0.0\n",
            "Máximo de 61: 1.0\n",
            "Mínimo de 61: 0.0\n",
            "Máximo de 62: 1.0\n",
            "Mínimo de 62: 0.0\n",
            "Máximo de 63: 1.0\n",
            "Mínimo de 63: 0.0\n",
            "Máximo de 64: 1.0\n",
            "Mínimo de 64: 0.0\n",
            "Máximo de 65: 1.0\n",
            "Mínimo de 65: 0.0\n",
            "Máximo de 66: 1.0\n",
            "Mínimo de 66: 0.0\n",
            "Máximo de 67: 1.0\n",
            "Mínimo de 67: 0.0\n",
            "Máximo de 68: 1.0\n",
            "Mínimo de 68: 0.0\n",
            "Máximo de 69: 1.0\n",
            "Mínimo de 69: 0.0\n",
            "Máximo de 70: 1.0\n",
            "Mínimo de 70: 0.0\n",
            "Máximo de 71: 1.0\n",
            "Mínimo de 71: 0.0\n",
            "Máximo de 72: 1.0\n",
            "Mínimo de 72: 0.0\n",
            "Máximo de 73: 1.0\n",
            "Mínimo de 73: 0.0\n",
            "Máximo de 74: 1.0\n",
            "Mínimo de 74: 0.0\n",
            "Máximo de 75: 1.0\n",
            "Mínimo de 75: 0.0\n",
            "Máximo de 76: 1.0\n",
            "Mínimo de 76: 0.0\n",
            "Máximo de 77: 1.0\n",
            "Mínimo de 77: 0.0\n",
            "Máximo de 78: 1.0\n",
            "Mínimo de 78: 0.0\n",
            "Máximo de 79: 1.0\n",
            "Mínimo de 79: 0.0\n",
            "Máximo de 80: 1.0\n",
            "Mínimo de 80: 0.0\n",
            "Máximo de 81: 1.0\n",
            "Mínimo de 81: 0.0\n",
            "Máximo de 82: 1.0\n",
            "Mínimo de 82: 0.0\n",
            "Máximo de 83: 1.0\n",
            "Mínimo de 83: 0.0\n",
            "Máximo de 84: 1.0\n",
            "Mínimo de 84: 0.0\n",
            "Máximo de 85: 1.0\n",
            "Mínimo de 85: 0.0\n",
            "Máximo de 86: 1.0\n",
            "Mínimo de 86: 0.0\n",
            "Máximo de 87: 1.0\n",
            "Mínimo de 87: 0.0\n",
            "Máximo de 88: 1.0\n",
            "Mínimo de 88: 0.0\n",
            "Máximo de 89: 1.0\n",
            "Mínimo de 89: 0.0\n",
            "Máximo de 90: 1.0\n",
            "Mínimo de 90: 0.0\n",
            "Máximo de 91: 1.0\n",
            "Mínimo de 91: 0.0\n",
            "Máximo de 92: 1.0\n",
            "Mínimo de 92: 0.0\n",
            "Máximo de 93: 1.0\n",
            "Mínimo de 93: 0.0\n",
            "Máximo de 94: 1.0\n",
            "Mínimo de 94: 0.0\n",
            "Máximo de 95: 1.0\n",
            "Mínimo de 95: 0.0\n",
            "Máximo de 96: 1.0\n",
            "Mínimo de 96: 0.0\n",
            "Máximo de 97: 1.0\n",
            "Mínimo de 97: 0.0\n",
            "Máximo de 98: 1.0\n",
            "Mínimo de 98: 0.0\n",
            "Máximo de 99: 1.0\n",
            "Mínimo de 99: 0.0\n",
            "Máximo de 100: 0.0\n",
            "Mínimo de 100: 0.0\n",
            "Máximo de 101: 1.0\n",
            "Mínimo de 101: 0.0\n",
            "Máximo de 102: 1.0\n",
            "Mínimo de 102: 0.0\n",
            "Máximo de 103: 1.0\n",
            "Mínimo de 103: 0.0\n",
            "Máximo de 104: 1.0\n",
            "Mínimo de 104: 0.0\n",
            "Máximo de 105: 1.0\n",
            "Mínimo de 105: 0.0\n",
            "Máximo de 106: 1.0\n",
            "Mínimo de 106: 0.0\n",
            "Máximo de 107: 1.0\n",
            "Mínimo de 107: 0.0\n",
            "Máximo de 108: 1.0\n",
            "Mínimo de 108: 0.0\n",
            "Máximo de 109: 1.0\n",
            "Mínimo de 109: 0.0\n",
            "Máximo de 110: 1.0\n",
            "Mínimo de 110: 0.0\n",
            "Máximo de 111: 0.36828599299829995\n",
            "Mínimo de 111: -0.19385776419649156\n",
            "Máximo de 112: 1.7795683589655225\n",
            "Mínimo de 112: -0.05854178907067193\n",
            "Máximo de 113: 0.3638401559951901\n",
            "Mínimo de 113: -0.10813635561343378\n",
            "Máximo de 114: 0.9611431436242899\n",
            "Mínimo de 114: -0.22992064225139075\n",
            "Máximo de 115: 0.2851052745077941\n",
            "Mínimo de 115: -0.2597540272895311\n",
            "Máximo de 116: 0.352043123123087\n",
            "Mínimo de 116: -0.0996090156002731\n",
            "Máximo de 117: 0.3709081489381011\n",
            "Mínimo de 117: -0.055746591747833626\n",
            "Máximo de 118: 0.3345205582775414\n",
            "Mínimo de 118: -0.18337161369288857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Esta impresión se realizó por que parece extraño que el modelo converja tan lento. Al leer la documentación oficial de sklearn, se llegó a la conclusión de que podía deberse a que el solver 'saga' necesita las columnas en los mismos rangos para garantizar la convergencia rápida. No obstante, dado que se ha normalizado teniendo en cuenta la naturaleza del dataset, todas las columnas no guardan los mismos rangos, si bien son cercanos. No obstante, se debería rehacer la implementación y probar aplicar normalización clásica en vez de tener en cuenta el máximo y el mínimo que nos proporciona el dataset.\n",
        "\n",
        "Para evitar un tiempo muy alto en gridsearch, se limitará a 100 el max_iter, a pesar de no poder garantizar la convergencia en la mayoría de los casos."
      ],
      "metadata": {
        "id": "LoPm9cuSSE6z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TOLERANCIA"
      ],
      "metadata": {
        "id": "Vf36T9b-c2fY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, tol=0.0001).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jnDW02tbc3cl",
        "outputId": "b63521e8-3a92-4d06-c92f-d19de551ea1e"
      },
      "execution_count": 130,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[729   2]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9298469387755102\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9972640218878249\n",
            "Puntuación:  0.49863201094391246\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La solución anterior representa la solución para la tolerancia predeterminada."
      ],
      "metadata": {
        "id": "ETV6hekaSrpP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, tol=10000).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WbP4UnG_dVdM",
        "outputId": "b2ba7cc7-d14f-4dc5-c4cf-18bd24095f10"
      },
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[730   1]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9311224489795918\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9986320109439124\n",
            "Puntuación:  0.4993160054719562\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, tol=0.00001).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KqFh-H-xdg5M",
        "outputId": "ae945881-21c1-4a63-9b46-61aa6c8ffd57"
      },
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[729   2]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9298469387755102\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9972640218878249\n",
            "Puntuación:  0.49863201094391246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, ni aumentar la tolerancia o bajarla drásticamente produce mejores resultados, así que se optará por tomar la predeterminada."
      ],
      "metadata": {
        "id": "5u1l6pnxSxLz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LOG REG WITH SGD"
      ],
      "metadata": {
        "id": "t-YBRn7qMwzR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAX ITER"
      ],
      "metadata": {
        "id": "vbXFwkuEMyg-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=10000, loss='log_loss', n_jobs=-1).fit(aux_train_data,aux_train_labels)\n",
        "print(w.n_iter_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CSZ-AoLXM1qN",
        "outputId": "cd6ffd06-9824-491a-b96d-29723b91ccbc"
      },
      "execution_count": 133,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iter2 = 100"
      ],
      "metadata": {
        "id": "TZt7KioDdpv-"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "En este caso parece que 100 será suficiente para garantizar la convergencia de los distintos modelos con SGD."
      ],
      "metadata": {
        "id": "5M-dO80_Tg-n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TOL"
      ],
      "metadata": {
        "id": "RW-oHVRudwMw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=0.001).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ags4FmGUdxEt",
        "outputId": "e1e24fbd-c7ea-4917-851d-c0d7d4e93390"
      },
      "execution_count": 135,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[727   4]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9272959183673469\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9945280437756497\n",
            "Puntuación:  0.49726402188782487\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La anterior es la tolerancia predeterminada por sklearn."
      ],
      "metadata": {
        "id": "3VvZU9dbTtld"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=10000).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WpdVMAqqeDkS",
        "outputId": "acdd3401-db42-4846-e566-9906a26058ce"
      },
      "execution_count": 136,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[729   2]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9298469387755102\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9972640218878249\n",
            "Puntuación:  0.49863201094391246\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=0.0001).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xS33jdLieFVd",
        "outputId": "644d7c9e-4b00-4832-90fe-3715489f6e46"
      },
      "execution_count": 137,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[703  28]\n",
            " [ 50   3]]\n",
            "Accuracy:  0.9005102040816326\n",
            "Sensitivity:  0.05660377358490566\n",
            "Specificity:  0.9616963064295485\n",
            "Puntuación:  0.5091500400072271\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Y como se puede observar, al igual que en el caso anterior, aumentarla o bajarla no produce ningún efecto, así que se deja predeterminada."
      ],
      "metadata": {
        "id": "4lqAbKK_TyCj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N_ITER_NO_CHANGE"
      ],
      "metadata": {
        "id": "XcQeP974eNrE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=0.001, n_iter_no_change=5).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmpjiHdkePKP",
        "outputId": "cd9b6e74-4998-4379-d1b1-672e8e348664"
      },
      "execution_count": 138,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[731   0]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9323979591836735\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Un valor de 5 es el predeterminado."
      ],
      "metadata": {
        "id": "o5isx7eMUCjT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=0.001, n_iter_no_change=1).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YNUHV-rDePVg",
        "outputId": "d8f39d60-d24a-414a-b0fe-888aee4ff317"
      },
      "execution_count": 139,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[730   1]\n",
            " [ 52   1]]\n",
            "Accuracy:  0.9323979591836735\n",
            "Sensitivity:  0.018867924528301886\n",
            "Specificity:  0.9986320109439124\n",
            "Puntuación:  0.5087499677361071\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, tol=0.001, n_iter_no_change=100).fit(aux_train_data,aux_train_labels)\n",
        "\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hbDB1_8uePgL",
        "outputId": "b07ea67a-fb1d-48e4-a648-fa56c1efe3cd"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[712  19]\n",
            " [ 53   0]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9740082079343365\n",
            "Puntuación:  0.48700410396716826\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Al disminuir o aumentar tampoco se obtienen mejores puntuaciones, así que se deja predeterminado."
      ],
      "metadata": {
        "id": "TmgTtfw5UFZt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PERCEPTRON"
      ],
      "metadata": {
        "id": "mZKvOqE5LCoP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### MAX ITER"
      ],
      "metadata": {
        "id": "HRa70WFRUTd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=10000).fit(aux_train_data,aux_train_labels)\n",
        "print(w.n_iter_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i5vkhGGOxUxd",
        "outputId": "3de65605-a5a4-4869-d2bb-a9284656ea7e"
      },
      "execution_count": 141,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "6\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iter3 = max_iter2"
      ],
      "metadata": {
        "id": "L2y7BHBeyiIG"
      },
      "execution_count": 142,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ya que los dos primeros métodos tienen 100 como número de iteraciones máximo, se dejará también el mismo a perceptron."
      ],
      "metadata": {
        "id": "oxNTxbyrUWCI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### TOL"
      ],
      "metadata": {
        "id": "Sghxy45rUiBh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, tol=0.001).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "\n",
        "##Están cambiados, mirar bien\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wAgpERb6zMYm",
        "outputId": "5c6df8a5-9631-4f57-fb40-d15489c464d8"
      },
      "execution_count": 143,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[710  21]\n",
            " [ 51   2]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.03773584905660377\n",
            "Specificity:  0.9712722298221614\n",
            "Puntuación:  0.5045040394393826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La anterior es la tolerancia predeterminada para Perceptron."
      ],
      "metadata": {
        "id": "YMi5Wi0KUlMI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, tol=10000).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yBMY5FaCzbUy",
        "outputId": "4a0e222c-83cd-43e1-c349-a7c21ea04928"
      },
      "execution_count": 144,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[710  21]\n",
            " [ 51   2]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.03773584905660377\n",
            "Specificity:  0.9712722298221614\n",
            "Puntuación:  0.5045040394393826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, tol=0.00001).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jV4Ol0iWzjvN",
        "outputId": "8e94e8c9-d173-4685-fb6a-fc029f19d055"
      },
      "execution_count": 145,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[710  21]\n",
            " [ 51   2]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.03773584905660377\n",
            "Specificity:  0.9712722298221614\n",
            "Puntuación:  0.5045040394393826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como ha ocurrido en los casos anteriores, ni aumentándola ni bajándola se consiguen mejores resultados, así que simplemente se toma la predeterminada."
      ],
      "metadata": {
        "id": "KvOWH21YUple"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N_ITER_NO_CHANGE"
      ],
      "metadata": {
        "id": "Bb_IQWalUwoI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, n_iter_no_change=5).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "id": "Ttp-p5eOKy7b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "84b9ffe0-0c91-435a-ab95-8927f16b83f0"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[710  21]\n",
            " [ 51   2]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.03773584905660377\n",
            "Specificity:  0.9712722298221614\n",
            "Puntuación:  0.5045040394393826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "La anterior ejecución correspondería al valor predeterminado."
      ],
      "metadata": {
        "id": "s0F6Ivi3VIfF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, n_iter_no_change=1).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "id": "EGAKIQZvK4RD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "93c36519-3e9b-4707-a820-f8f68f0e8045"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[713  18]\n",
            " [ 52   1]]\n",
            "Accuracy:  0.9107142857142857\n",
            "Sensitivity:  0.018867924528301886\n",
            "Specificity:  0.9753761969904241\n",
            "Puntuación:  0.497122060759363\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(n_jobs=-1, early_stopping=True, max_iter=max_iter3, n_iter_no_change=100).fit(aux_train_data,aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "id": "NPE5WpIBK6Ux",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11eff23e-31a7-45d1-cd12-2ebdbe0841e7"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[658  73]\n",
            " [ 44   9]]\n",
            "Accuracy:  0.8507653061224489\n",
            "Sensitivity:  0.16981132075471697\n",
            "Specificity:  0.9001367989056087\n",
            "Puntuación:  0.5349740598301629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede ovservar aumentar este parámetro drásticamente a aumentado un poco la puntuación, así que para Perceptron, se usará 100 como valor."
      ],
      "metadata": {
        "id": "cHQr9gv3VOqU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## GRID SEARCH"
      ],
      "metadata": {
        "id": "lZFVH8pjKxsi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se va a ejecutar el 5-fold cross-validation para todas las posibles combinaciones de algoritmos que hemos considerado. Debido a limitaciones de tiempo y capacidad de cómputo, solo se pudo probar con tres valores diferentes para la tasa de aprendizaje y un par de valores para el factor de regularización. Sin embargo, me habría gustado probar con más opciones para obtener una mayor variedad.\n",
        "\n",
        "Para seleccionar automáticamente el mejor algoritmo, utilizaré el criterio de puntuación. Esto significa que compararé los resultados de cada algoritmo utilizando el promedio entre los 0 bien clasificados y los 1 bien clasificados, y seleccionaré el algoritmo que obtenga la puntuación más alta según esa métrica como el mejor. "
      ],
      "metadata": {
        "id": "4oN55i7yXj1-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_puntuacion = -np.inf\n",
        "best_algoritmo = 'ERROR'\n",
        "\n",
        "for num_algoritmo in range(24):\n",
        "  mean_accuracy = 0\n",
        "  mean_sensitivity = 0\n",
        "  mean_specificity = 0\n",
        "  mean_matrix = np.zeros((2,2))\n",
        "  for i in range(5):\n",
        "    train_x = X_train.iloc[cv_trains[i]].to_numpy()\n",
        "    train_y = y_train.iloc[cv_trains[i]].to_numpy().flatten()\n",
        "    test_x = X_train.iloc[cv_tests[i]].to_numpy()\n",
        "    test_y = y_train.iloc[cv_tests[i]].to_numpy().flatten()\n",
        "\n",
        "    if(num_algoritmo == 0): \n",
        "      w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, penalty='l1', C=100)\n",
        "      algoritmo = \"LogisticRegression con penalty=l1, C=100\"\n",
        "    if(num_algoritmo == 1): \n",
        "      w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, penalty='l1', C=0.01)\n",
        "      algoritmo = \"LogisticRegression con penalty=l1, C=0.01\"\n",
        "    if(num_algoritmo == 2): \n",
        "      w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, penalty='l2', C=100)\n",
        "      algoritmo = \"LogisticRegression con penalty=l2, C=100\"\n",
        "    if(num_algoritmo == 3): \n",
        "      w = LogisticRegression(max_iter=max_iter1, solver='saga', n_jobs=-1, penalty='l2', C=0.01)\n",
        "      algoritmo = \"LogisticRegression con penalty=l2, C=0.01\"\n",
        "\n",
        "    if(num_algoritmo == 4): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l1', alpha=0.01, eta0=0.001, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l1', alpha=0.01, eta0=0.001\"\n",
        "    if(num_algoritmo == 5): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l1', alpha=0.01, eta0=1, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l1', alpha=0.01, eta0=1\"\n",
        "    if(num_algoritmo == 6): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l1', alpha=10, eta0=0.001, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l1', alpha=10, eta0=0.001\"\n",
        "    if(num_algoritmo == 7): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l1', alpha=10, eta0=1, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l1', alpha=10, eta0=1\"\n",
        "    if(num_algoritmo == 8): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.01, eta0=0.001, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l2', alpha=0.01, eta0=0.001\"\n",
        "    if(num_algoritmo == 9): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.01, eta0=1, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l2', alpha=0.01, eta0=1\"\n",
        "    if(num_algoritmo == 10): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=10, eta0=0.001, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l2', alpha=10, eta0=0.001\"\n",
        "    if(num_algoritmo == 11): \n",
        "      w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=10, eta0=1, n_iter_no_change=100)\n",
        "      algoritmo = \"Perceptron con penalty='l2', alpha=10, eta0=1\"\n",
        "\n",
        "    if(num_algoritmo == 12): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=0.01, eta0=0.001, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, eta0=0.001\"\n",
        "    if(num_algoritmo == 13): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=0.01, eta0=1, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, eta0=1\"\n",
        "    if(num_algoritmo == 14): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=0.01, learning_rate='optimal')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal'\"\n",
        "    if(num_algoritmo == 15): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=10, eta0=0.001, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=10, eta0=0.001\"\n",
        "    if(num_algoritmo == 16): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=10, eta0=1, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=10, eta0=1\"\n",
        "    if(num_algoritmo == 17): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l1', alpha=10, learning_rate='optimal')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal'\"\n",
        "    if(num_algoritmo == 18): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=0.01, eta0=0.001, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l2', alpha=0.01, eta0=0.001\"\n",
        "    if(num_algoritmo == 19): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=0.01, eta0=1, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l2', alpha=0.01, eta0=1\"\n",
        "    if(num_algoritmo == 20): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=0.01, learning_rate='optimal')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal'\"\n",
        "    if(num_algoritmo == 21): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=10, eta0=0.001, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l2', alpha=10, eta0=0.001\"\n",
        "    if(num_algoritmo == 22): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=10, eta0=1, learning_rate='constant')\n",
        "      algoritmo = \"SGDClassifier con penalty='l2', alpha=10, eta0=1\"\n",
        "    if(num_algoritmo == 23): \n",
        "      w = SGDClassifier(max_iter=max_iter2, loss='log_loss', n_jobs=-1, penalty='l2', alpha=10, learning_rate='optimal')\n",
        "      algoritmo = \"SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal'\"\n",
        "\n",
        "    w = w.fit(train_x, train_y)\n",
        "    y_predicted = w.predict(test_x)\n",
        "\n",
        "    accuracy = metrics.accuracy_score(test_y, y_predicted)\n",
        "    matriz_de_confusion = metrics.confusion_matrix(test_y, y_predicted)\n",
        "    specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "    sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "    mean_accuracy += accuracy\n",
        "    mean_matrix += matriz_de_confusion\n",
        "    mean_sensitivity += sensitivity\n",
        "    mean_specificity += specificity\n",
        "\n",
        "  puntuacion = puntuar(mean_sensitivity/5, mean_specificity/5)\n",
        "\n",
        "  print('Algoritmo ', num_algoritmo, ' : ', algoritmo, '----------------')\n",
        "  print('Accuracy: ', mean_accuracy/5)\n",
        "  print('Sensitivity: ', mean_sensitivity/5)\n",
        "  print('Specificity: ', mean_specificity/5)\n",
        "  print('Puntuación: ', puntuacion)\n",
        "  print()\n",
        "\n",
        "  if(puntuacion > best_puntuacion):\n",
        "    best_puntuacion = puntuacion\n",
        "    best_algoritmo = algoritmo\n",
        "\n",
        "print('El algoritmo que mejores resultados nos ha dado es el ', best_algoritmo, ', con una puntuación de ', best_puntuacion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J4zOkzb105n9",
        "outputId": "e8b220ff-8444-4d18-e2ce-6877ae98493b"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  0  :  LogisticRegression con penalty=l1, C=100 ----------------\n",
            "Accuracy:  0.9401808867141883\n",
            "Sensitivity:  0.008602150537634409\n",
            "Specificity:  0.9987826869817498\n",
            "Puntuación:  0.5036924187596921\n",
            "\n",
            "Algoritmo  1  :  LogisticRegression con penalty=l1, C=0.01 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  2  :  LogisticRegression con penalty=l2, C=100 ----------------\n",
            "Accuracy:  0.9401808867141883\n",
            "Sensitivity:  0.008602150537634409\n",
            "Specificity:  0.9987826869817498\n",
            "Puntuación:  0.5036924187596921\n",
            "\n",
            "Algoritmo  3  :  LogisticRegression con penalty=l2, C=0.01 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  4  :  Perceptron con penalty='l1', alpha=0.01, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  5  :  Perceptron con penalty='l1', alpha=0.01, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  6  :  Perceptron con penalty='l1', alpha=10, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  7  :  Perceptron con penalty='l1', alpha=10, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  8  :  Perceptron con penalty='l2', alpha=0.01, eta0=0.001 ----------------\n",
            "Accuracy:  0.9065886463136719\n",
            "Sensitivity:  0.05806451612903226\n",
            "Specificity:  0.9599675566180931\n",
            "Puntuación:  0.5090160363735626\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  9  :  Perceptron con penalty='l2', alpha=0.01, eta0=1 ----------------\n",
            "Accuracy:  0.92427352960708\n",
            "Sensitivity:  0.015053763440860216\n",
            "Specificity:  0.9814693027600663\n",
            "Puntuación:  0.4982615331004632\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  10  :  Perceptron con penalty='l2', alpha=10, eta0=0.001 ----------------\n",
            "Accuracy:  0.92427352960708\n",
            "Sensitivity:  0.015053763440860216\n",
            "Specificity:  0.9814693027600663\n",
            "Puntuación:  0.4982615331004632\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Algoritmo  11  :  Perceptron con penalty='l2', alpha=10, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  12  :  SGDClassifier con penalty='l1', alpha=0.01, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  13  :  SGDClassifier con penalty='l1', alpha=0.01, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  14  :  SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal' ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  15  :  SGDClassifier con penalty='l1', alpha=10, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  16  :  SGDClassifier con penalty='l1', alpha=10, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  17  :  SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal' ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  18  :  SGDClassifier con penalty='l2', alpha=0.01, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  19  :  SGDClassifier con penalty='l2', alpha=0.01, eta0=1 ----------------\n",
            "Accuracy:  0.8301891957117149\n",
            "Sensitivity:  0.15913978494623654\n",
            "Specificity:  0.8723979648319595\n",
            "Puntuación:  0.5157688748890981\n",
            "\n",
            "Algoritmo  20  :  SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal' ----------------\n",
            "Accuracy:  0.9406897925666055\n",
            "Sensitivity:  0.0\n",
            "Specificity:  0.9998646820027064\n",
            "Puntuación:  0.4999323410013532\n",
            "\n",
            "Algoritmo  21  :  SGDClassifier con penalty='l2', alpha=10, eta0=0.001 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  22  :  SGDClassifier con penalty='l2', alpha=10, eta0=1 ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "Algoritmo  23  :  SGDClassifier con penalty='l1', alpha=0.01, learning_rate='optimal' ----------------\n",
            "Accuracy:  0.9408171000140912\n",
            "Sensitivity:  0.0\n",
            "Specificity:  1.0\n",
            "Puntuación:  0.5\n",
            "\n",
            "El algoritmo que mejores resultados nos ha dado es el  SGDClassifier con penalty='l2', alpha=0.01, eta0=1 , con una puntuación de  0.5157688748890981\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Es sorprendente que el algoritmo Perceptrón haya resultado ser el que ofrece los mejores resultados en este caso. Aunque el Perceptrón no es conocido por ser especialmente eficaz en la clasificación de conjuntos de datos no linealmente separables y no tiene un mecanismo implementado para minimizar la función de pérdida, puede ser precisamente esta falta de complejidad lo que ha contribuido a obtener mejores resultados en nuestro caso específico.\n",
        "\n",
        "Es importante recordar que el criterio de selección utilizado no es la precisión (Accuracy), sino una \"puntuación\" que también tiene en cuenta la especificidad (Specificity). Dado el desbalance de los datos, los algoritmos de regresión lineal tienden a darle menos importancia a la correcta clasificación de la clase minoritaria. Esto podría haberse intentado abordar mediante la asignación de pesos a las clases.\n",
        "\n",
        "En cualquier caso, aunque existe la posibilidad de mejorar lo suficiente un clasificador logístico como para superar al Perceptrón, los resultados empíricos actuales muestran que el Perceptrón ha brindado mejores resultados. Por lo tanto, continuaremos utilizando este algoritmo para el resto de la práctica. Sin embargo, sería interesante explorar las otras opciones en un futuro con más tiempo disponible, para determinar si se pueden obtener mejores resultados."
      ],
      "metadata": {
        "id": "wZy1oebOYMCU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Procesado tras GridSearch"
      ],
      "metadata": {
        "id": "WEzWSEOnYNeN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### alpha"
      ],
      "metadata": {
        "id": "6c20mNt1gA1B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para 'alpha' ha resultado ser mejor un valor pequeño, y para 'eta0', también, por lo que vamos a explorar configuraciones cercanas para quedarnos con la opción que mejores resultados consiga.\n",
        "\n",
        "Después, probaremos a añadirle pesos a las clases y estudiar qué pesos pueden darnos mejores resultados."
      ],
      "metadata": {
        "id": "gYAVVB29oACC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.01, eta0=0.001, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QesTVP93oEi7",
        "outputId": "f5eb30bf-651c-4202-dba4-1a93f4448a69"
      },
      "execution_count": 150,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[649  82]\n",
            " [ 42  11]]\n",
            "Accuracy:  0.8418367346938775\n",
            "Sensitivity:  0.20754716981132076\n",
            "Specificity:  0.8878248974008208\n",
            "Puntuación:  0.5476860336060708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este es el valor de puntuación de referencia, con el alpha que nos ha proporcionado GridSearch."
      ],
      "metadata": {
        "id": "-iW8uCocYUSh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.001, eta0=0.001, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDJT8KaModf5",
        "outputId": "cff2e2d3-f3bd-4f60-9602-f4708f12c27b"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[534 197]\n",
            " [ 34  19]]\n",
            "Accuracy:  0.7053571428571429\n",
            "Sensitivity:  0.3584905660377358\n",
            "Specificity:  0.7305061559507524\n",
            "Puntuación:  0.5444983609942441\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.1, eta0=0.001, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNnXxKEno5kx",
        "outputId": "431e38f3-2edc-440d-f867-6eb6ae404436"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[616 115]\n",
            " [ 41  12]]\n",
            "Accuracy:  0.8010204081632653\n",
            "Sensitivity:  0.22641509433962265\n",
            "Specificity:  0.8426812585499316\n",
            "Puntuación:  0.5345481764447771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.0001, eta0=0.001, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DRBHyh67ooLd",
        "outputId": "96e0ca4d-7937-43da-8a6b-8f8f8f081b3a"
      },
      "execution_count": 153,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[692  39]\n",
            " [ 47   6]]\n",
            "Accuracy:  0.8903061224489796\n",
            "Sensitivity:  0.11320754716981132\n",
            "Specificity:  0.9466484268125855\n",
            "Puntuación:  0.5299279869911985\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=0.00001, eta0=0.001,n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qsIL4OZ2orvn",
        "outputId": "461b9e1b-9390-4497-d024-64a8e53c3151"
      },
      "execution_count": 154,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[658  73]\n",
            " [ 44   9]]\n",
            "Accuracy:  0.8507653061224489\n",
            "Sensitivity:  0.16981132075471697\n",
            "Specificity:  0.9001367989056087\n",
            "Puntuación:  0.5349740598301629\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como se puede observar, ni bajar ni subir el parámetro alpha ha conseguido mostrar mejores resultados de forma consistente en la puntuación, así que se deja alpha tal y como se ha obtenido a partir de Grid Search."
      ],
      "metadata": {
        "id": "AZpGUH29Y2-U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "alpha = 0.01"
      ],
      "metadata": {
        "id": "hjZ_pPx6ou_k"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### eta0"
      ],
      "metadata": {
        "id": "NtLn1ZzkpFGg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=0.001, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IHoVXbHjpHHI",
        "outputId": "21bfa44d-1e3d-46c6-a09f-d6ed15dce157"
      },
      "execution_count": 156,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[649  82]\n",
            " [ 42  11]]\n",
            "Accuracy:  0.8418367346938775\n",
            "Sensitivity:  0.20754716981132076\n",
            "Specificity:  0.8878248974008208\n",
            "Puntuación:  0.5476860336060708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Este es el valor que se toma como referencia."
      ],
      "metadata": {
        "id": "hbv74JLBZGHj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=0.01, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HYaEolDDpaGl",
        "outputId": "7be9c494-e50f-4e4a-a1ba-cde48136dbdb"
      },
      "execution_count": 157,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[616 115]\n",
            " [ 41  12]]\n",
            "Accuracy:  0.8010204081632653\n",
            "Sensitivity:  0.22641509433962265\n",
            "Specificity:  0.8426812585499316\n",
            "Puntuación:  0.5345481764447771\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=0.0001).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "at4zKUjNpd8L",
        "outputId": "f8e7f643-9f62-40aa-b0fe-e471140bec34"
      },
      "execution_count": 158,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[687  44]\n",
            " [ 46   7]]\n",
            "Accuracy:  0.8852040816326531\n",
            "Sensitivity:  0.1320754716981132\n",
            "Specificity:  0.9398084815321477\n",
            "Puntuación:  0.5359419766151304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=0.1).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P1kYSwypn2G",
        "outputId": "365a5b2d-257a-4a98-fb0f-4e97f9325087"
      },
      "execution_count": 159,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[676  55]\n",
            " [ 46   7]]\n",
            "Accuracy:  0.8711734693877551\n",
            "Sensitivity:  0.1320754716981132\n",
            "Specificity:  0.9247606019151847\n",
            "Puntuación:  0.528418036806649\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=0.00001).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DSSdO751pqqi",
        "outputId": "ef109e1b-dcff-4707-a657-c1af1b2848ab"
      },
      "execution_count": 160,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[710  21]\n",
            " [ 51   2]]\n",
            "Accuracy:  0.9081632653061225\n",
            "Sensitivity:  0.03773584905660377\n",
            "Specificity:  0.9712722298221614\n",
            "Puntuación:  0.5045040394393826\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como tampoco se ha logrado mejorar lo que ya había, se toma el que ha resultado tras Grid Search."
      ],
      "metadata": {
        "id": "zfr8zDJbZXMY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "eta0 = 0.001"
      ],
      "metadata": {
        "id": "XiTtX55Gpue1"
      },
      "execution_count": 161,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### class_weigth"
      ],
      "metadata": {
        "id": "oyCS3t8vp2G9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight=None, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u3QKHEjop3vS",
        "outputId": "b0f25183-6c7f-4c38-ad66-87b4e428f647"
      },
      "execution_count": 162,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[649  82]\n",
            " [ 42  11]]\n",
            "Accuracy:  0.8418367346938775\n",
            "Sensitivity:  0.20754716981132076\n",
            "Specificity:  0.8878248974008208\n",
            "Puntuación:  0.5476860336060708\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight='balanced', n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xmNN2U2tp3yq",
        "outputId": "d899a457-83ea-46f7-955b-f1403c366b3a"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[588 143]\n",
            " [ 35  18]]\n",
            "Accuracy:  0.7729591836734694\n",
            "Sensitivity:  0.33962264150943394\n",
            "Specificity:  0.8043775649794802\n",
            "Puntuación:  0.572000103244457\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight={0:0.3, 1:0.7}, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_Vp_xuwqNff",
        "outputId": "6cfe363b-417b-4ea6-bbea-439f1adaa593"
      },
      "execution_count": 164,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[654  77]\n",
            " [ 40  13]]\n",
            "Accuracy:  0.8507653061224489\n",
            "Sensitivity:  0.24528301886792453\n",
            "Specificity:  0.8946648426812586\n",
            "Puntuación:  0.5699739307745916\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight={0:0.2, 1:0.8}, n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtvRyE7Fqc00",
        "outputId": "edb8834d-0312-40ba-9e8f-f5d08ff07824"
      },
      "execution_count": 165,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[691  40]\n",
            " [ 48   5]]\n",
            "Accuracy:  0.8877551020408163\n",
            "Sensitivity:  0.09433962264150944\n",
            "Specificity:  0.945280437756498\n",
            "Puntuación:  0.5198100301990037\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight={0:0.05, 1:0.95},n_iter_no_change=100).fit(aux_train_data, aux_train_labels)\n",
        "y_predicted = w.predict(aux_test_data)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(aux_test_labels, y_predicted)\n",
        "accuracy = metrics.accuracy_score(aux_test_labels, y_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(matriz_de_confusion)\n",
        "print('Accuracy: ', accuracy)\n",
        "print('Sensitivity: ', sensitivity)\n",
        "print('Specificity: ', specificity)\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6Y7qOneqjFj",
        "outputId": "6f45c513-2ff0-4823-e37d-ef1bf4c9e6e3"
      },
      "execution_count": 166,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[569 162]\n",
            " [ 35  18]]\n",
            "Accuracy:  0.7487244897959183\n",
            "Sensitivity:  0.33962264150943394\n",
            "Specificity:  0.7783857729138167\n",
            "Puntuación:  0.5590042072116254\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Con balance como class_weight, se ha logrado mejorar bastante la puntuación, así que se toma esta como referencia.\n",
        "\n",
        "*The “balanced” mode uses the values of y to automatically adjust weights inversely proportional to class frequencies in the input data as n_samples / (n_classes * np.bincount(y)).* Extraído de la documentación oficial de sklearn.\n"
      ],
      "metadata": {
        "id": "zuih9LWkrbfa"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>7)  Selección de la mejor hipótesis para el problema. Discuta el enfoque seguido y el criterio de selección usado. ¿Cúal es su error $E_{out}$? 1 punto."
      ],
      "metadata": {
        "id": "wUknqHBtg8DP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para seleccionar la mejor hipótesis entre todas las obtenidas, normalmente se tiende a utilizar la métrica de precisión (Accuracy). Sin embargo, en este caso, es importante considerar aspectos más profundos, como la especificidad (Specificity) y la sensibilidad (Sensitivity).\n",
        "\n",
        "Se ha utilizado una métrica llamada 'puntuación', que es la media aritmética entre la sensitividad y la especificidad. Utilizando esta puntuación, hemos seleccionado la mejor solución entre las hipótesis generadas.\n",
        "\n",
        "Finalmente, ha resultado el algoritmo que se ha comentado en Grid Search."
      ],
      "metadata": {
        "id": "e31eUApDbFQl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "g = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight='balanced', n_iter_no_change=100)\n",
        "g = g.fit(X_train, y_train)\n",
        "# X_train_prueba = X_train.loc[:, (X_train != '0').any()]\n",
        "# X_train_prueba"
      ],
      "metadata": {
        "id": "qN7qVN3Eg9R_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "be221a61-517a-4631-a942-1a6a2a30e85a"
      },
      "execution_count": 167,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_stochastic_gradient.py:702: ConvergenceWarning: Maximum number of iteration reached before convergence. Consider increasing max_iter to improve the fit.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Se hacen las transformaciones hechas a train a test, exactamente en el mismo orden y con los mismos resultados."
      ],
      "metadata": {
        "id": "VwsFUx4fsAeD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_final = X_test\n",
        "X_test_final.columns = X_test_final.columns.astype(str)\n",
        "\n",
        "columnas3 = [str(i) for i in range(64,85,1)]\n",
        "columnas1 = ['1']\n",
        "columnas2 = ['2']\n",
        "\n",
        "#Se normaliza tomando como máximo y mínimo los que se nos dan en la información del dataset\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnas1, 6, 1)\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnas2, 10, 1)\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnas3, 12, 1)\n",
        "\n",
        "numericos = X_test_final.iloc[:, [1, 2] + [i for i in range(64,85,1)]]\n",
        "\n",
        "numericos = pd.DataFrame(modelo_pca.transform(numericos))\n",
        "\n",
        "L0 = [i for i in range(1,42)]\n",
        "L2 = [i for i in range(1,11)]\n",
        "\n",
        "X_test_final = aplicar_one_hot_encoding(X_test_final, '0', L0)\n",
        "print(X_test_final.shape)\n",
        "\n",
        "X_test_final = aplicar_one_hot_encoding(X_test_final, '4', L2)\n",
        "print(X_test_final.shape)\n",
        "\n",
        "columnasL1 = ['3']\n",
        "columnasL3 = [str(i) for i in range(5,47,1)]\n",
        "columnasL4 = [str(i) for i in range(43,68,1)]\n",
        "\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnasL1, 6, 1)\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnasL3, 9, 0)\n",
        "X_test_final = aplicar_min_max_scaler(X_test_final, columnasL1, 9, 0)\n",
        "\n",
        "columnas_a_eliminar = ['1', '2']\n",
        "columnas_a_eliminar.extend([str(i) for i in range(64,85,1)])\n",
        "\n",
        "# Eliminar las columnas por su nombre\n",
        "X_test_final = X_test_final.drop(columns=columnas_a_eliminar)\n",
        "print(X_test_final.shape)\n",
        "\n",
        "X_test_final = X_test_final.to_numpy()\n",
        "numericos = numericos.to_numpy()\n",
        "X_test_final = pd.DataFrame(X_test_final)\n",
        "numericos = pd.DataFrame(numericos)\n",
        "\n",
        "X_test_final = pd.concat([X_test_final, numericos], axis=1)\n",
        "X_test_final = X_test_final.to_numpy()\n",
        "X_test_final = pd.DataFrame(X_test_final)\n",
        "\n",
        "X_test_final\n"
      ],
      "metadata": {
        "id": "1SLtJKneOgYW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 540
        },
        "outputId": "6fa68f03-b6c7-426c-d82b-2f2934251c8e"
      },
      "execution_count": 168,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1965, 125)\n",
            "(1965, 134)\n",
            "(1965, 111)\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           0         1         2         3         4         5         6    \\\n",
              "0     0.044444  0.111111  0.666667  0.222222  0.222222  0.777778  0.111111   \n",
              "1     0.022222  0.000000  0.555556  0.222222  0.222222  0.111111  0.444444   \n",
              "2     0.044444  0.111111  0.555556  0.111111  0.333333  0.555556  0.111111   \n",
              "3     0.066667  0.000000  0.444444  0.000000  0.555556  0.555556  0.000000   \n",
              "4     0.044444  0.000000  0.333333  0.000000  0.666667  0.333333  0.222222   \n",
              "...        ...       ...       ...       ...       ...       ...       ...   \n",
              "1960  0.022222  0.111111  0.444444  0.222222  0.333333  0.444444  0.111111   \n",
              "1961  0.044444  0.222222  0.333333  0.111111  0.555556  0.555556  0.222222   \n",
              "1962  0.022222  0.000000  0.666667  0.111111  0.222222  0.111111  0.222222   \n",
              "1963  0.066667  0.000000  0.555556  0.222222  0.333333  0.555556  0.111111   \n",
              "1964  0.044444  0.222222  0.444444  0.111111  0.333333  0.333333  0.222222   \n",
              "\n",
              "           7         8         9    ...  109  110       111       112  \\\n",
              "0     0.222222  0.000000  0.333333  ...  1.0  0.0  0.034968 -0.022240   \n",
              "1     0.555556  0.555556  0.444444  ...  0.0  0.0 -0.186471 -0.017338   \n",
              "2     0.444444  0.333333  0.333333  ...  0.0  0.0 -0.076024 -0.020861   \n",
              "3     0.444444  0.333333  0.222222  ...  0.0  0.0  0.034968 -0.022240   \n",
              "4     0.444444  0.333333  0.222222  ...  0.0  0.0 -0.077813 -0.020350   \n",
              "...        ...       ...       ...  ...  ...  ...       ...       ...   \n",
              "1960  0.444444  0.444444  0.444444  ...  0.0  0.0 -0.079743 -0.017439   \n",
              "1961  0.222222  0.222222  0.444444  ...  0.0  0.0 -0.076024 -0.020861   \n",
              "1962  0.666667  0.555556  0.333333  ...  0.0  0.0 -0.185933 -0.017690   \n",
              "1963  0.444444  0.333333  0.444444  ...  0.0  0.0 -0.073689 -0.019228   \n",
              "1964  0.555556  0.555556  0.333333  ...  0.0  0.0 -0.077813 -0.020350   \n",
              "\n",
              "           113       114       115       116       117       118  \n",
              "0    -0.077205 -0.020551  0.006991 -0.004363 -0.009689  0.012107  \n",
              "1     0.089887  0.017650  0.114716  0.124514  0.005495 -0.004096  \n",
              "2    -0.078915 -0.017168  0.006312 -0.001798 -0.008372  0.012804  \n",
              "3    -0.077205 -0.020551  0.006991 -0.004363 -0.009689  0.012107  \n",
              "4     0.073216  0.014183  0.004421 -0.020613  0.000502 -0.001355  \n",
              "...        ...       ...       ...       ...       ...       ...  \n",
              "1960  0.036605 -0.067907  0.013197 -0.022374  0.000563  0.007752  \n",
              "1961 -0.078915 -0.017168  0.006312 -0.001798 -0.008372  0.012804  \n",
              "1962  0.091023  0.019667  0.117906  0.125416  0.003607  0.002328  \n",
              "1963 -0.060533 -0.017084  0.117286  0.140765 -0.004696  0.009365  \n",
              "1964  0.073216  0.014183  0.004421 -0.020613  0.000502 -0.001355  \n",
              "\n",
              "[1965 rows x 119 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32868ed7-68ad-4121-b27d-6a754cb60e6f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>109</th>\n",
              "      <th>110</th>\n",
              "      <th>111</th>\n",
              "      <th>112</th>\n",
              "      <th>113</th>\n",
              "      <th>114</th>\n",
              "      <th>115</th>\n",
              "      <th>116</th>\n",
              "      <th>117</th>\n",
              "      <th>118</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.777778</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034968</td>\n",
              "      <td>-0.022240</td>\n",
              "      <td>-0.077205</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>0.006991</td>\n",
              "      <td>-0.004363</td>\n",
              "      <td>-0.009689</td>\n",
              "      <td>0.012107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.186471</td>\n",
              "      <td>-0.017338</td>\n",
              "      <td>0.089887</td>\n",
              "      <td>0.017650</td>\n",
              "      <td>0.114716</td>\n",
              "      <td>0.124514</td>\n",
              "      <td>0.005495</td>\n",
              "      <td>-0.004096</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.076024</td>\n",
              "      <td>-0.020861</td>\n",
              "      <td>-0.078915</td>\n",
              "      <td>-0.017168</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>-0.001798</td>\n",
              "      <td>-0.008372</td>\n",
              "      <td>0.012804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.034968</td>\n",
              "      <td>-0.022240</td>\n",
              "      <td>-0.077205</td>\n",
              "      <td>-0.020551</td>\n",
              "      <td>0.006991</td>\n",
              "      <td>-0.004363</td>\n",
              "      <td>-0.009689</td>\n",
              "      <td>0.012107</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.077813</td>\n",
              "      <td>-0.020350</td>\n",
              "      <td>0.073216</td>\n",
              "      <td>0.014183</td>\n",
              "      <td>0.004421</td>\n",
              "      <td>-0.020613</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>-0.001355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1960</th>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.079743</td>\n",
              "      <td>-0.017439</td>\n",
              "      <td>0.036605</td>\n",
              "      <td>-0.067907</td>\n",
              "      <td>0.013197</td>\n",
              "      <td>-0.022374</td>\n",
              "      <td>0.000563</td>\n",
              "      <td>0.007752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1961</th>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.076024</td>\n",
              "      <td>-0.020861</td>\n",
              "      <td>-0.078915</td>\n",
              "      <td>-0.017168</td>\n",
              "      <td>0.006312</td>\n",
              "      <td>-0.001798</td>\n",
              "      <td>-0.008372</td>\n",
              "      <td>0.012804</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1962</th>\n",
              "      <td>0.022222</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.185933</td>\n",
              "      <td>-0.017690</td>\n",
              "      <td>0.091023</td>\n",
              "      <td>0.019667</td>\n",
              "      <td>0.117906</td>\n",
              "      <td>0.125416</td>\n",
              "      <td>0.003607</td>\n",
              "      <td>0.002328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1963</th>\n",
              "      <td>0.066667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.073689</td>\n",
              "      <td>-0.019228</td>\n",
              "      <td>-0.060533</td>\n",
              "      <td>-0.017084</td>\n",
              "      <td>0.117286</td>\n",
              "      <td>0.140765</td>\n",
              "      <td>-0.004696</td>\n",
              "      <td>0.009365</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1964</th>\n",
              "      <td>0.044444</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.111111</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.222222</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>-0.077813</td>\n",
              "      <td>-0.020350</td>\n",
              "      <td>0.073216</td>\n",
              "      <td>0.014183</td>\n",
              "      <td>0.004421</td>\n",
              "      <td>-0.020613</td>\n",
              "      <td>0.000502</td>\n",
              "      <td>-0.001355</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1965 rows × 119 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32868ed7-68ad-4121-b27d-6a754cb60e6f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32868ed7-68ad-4121-b27d-6a754cb60e6f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32868ed7-68ad-4121-b27d-6a754cb60e6f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "labels_predicted = g.predict(X_test_final)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(y_test, labels_predicted)\n",
        "accuracy = metrics.accuracy_score(y_test, labels_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(\"-------------Resultados obtenidos:----------------\")\n",
        "print('Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)')\n",
        "print(matriz_de_confusion)\n",
        "print()\n",
        "print('Accuracy: ', accuracy*100, '%')\n",
        "print('Sensitivity: ', sensitivity*100, '%')\n",
        "print('Specificity: ', specificity*100, '%')\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity)*100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY92hQDZwTeQ",
        "outputId": "1adc503e-7a2f-4c02-a563-8e7952421373"
      },
      "execution_count": 169,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------Resultados obtenidos:----------------\n",
            "Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)\n",
            "[[1350  494]\n",
            " [  66   55]]\n",
            "\n",
            "Accuracy:  71.50127226463104 %\n",
            "Sensitivity:  45.45454545454545 %\n",
            "Specificity:  73.21041214750542 %\n",
            "Puntuación:  59.33247880102543 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para evaluar la calidad de nuestros resultados, es importante compararlos con baselines. Estos baselines son estimadores que utilizan heurísticas simples para determinar cómo podríamos clasificar los datos sin entrenar un modelo complejo. Dado que solo necesitamos una referencia básica, optaremos por estimadores ingenuos que utilizan enfoques muy sencillos.\n",
        "\n",
        "En este caso, utilizaremos dos estimadores ingenuos. Uno de ellos siempre predice la clase negativa ('0'), mientras que el otro siempre predice la clase positiva ('1'). Luego compararemos las métricas de precisión (Accuracy) y puntuación (Puntuación) de estos estimadores con nuestros resultados.\n",
        "\n",
        "Este enfoque nos dará una idea de cómo se desempeñan nuestros modelos en comparación con las predicciones basadas en heurísticas básicas."
      ],
      "metadata": {
        "id": "OmPU_NGbcr5v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"-------------Resultados obtenidos por nuestro clasificador:----------------\")\n",
        "print('Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)')\n",
        "print(matriz_de_confusion)\n",
        "print()\n",
        "print('Accuracy: ', accuracy*100, '%')\n",
        "print('Sensitivity: ', sensitivity*100, '%')\n",
        "print('Specificity: ', specificity*100, '%')\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity)*100, '%')\n",
        "\n",
        "labels_predicted = np.full(X_test_final.shape[0],1)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(y_test, labels_predicted)\n",
        "accuracy = metrics.accuracy_score(y_test, labels_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(\"-------------Resultados obtenidos por el clasificador 'todo si':----------------\")\n",
        "print('Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)')\n",
        "print(matriz_de_confusion)\n",
        "print()\n",
        "print('Accuracy: ', accuracy*100, '%')\n",
        "print('Sensitivity: ', sensitivity*100, '%')\n",
        "print('Specificity: ', specificity*100, '%')\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity)*100, '%')\n",
        "\n",
        "\n",
        "labels_predicted = np.full(X_test_final.shape[0],0)\n",
        "\n",
        "matriz_de_confusion = metrics.confusion_matrix(y_test, labels_predicted)\n",
        "accuracy = metrics.accuracy_score(y_test, labels_predicted)\n",
        "specificity = matriz_de_confusion[0,0]/matriz_de_confusion[0].sum()\n",
        "sensitivity = matriz_de_confusion[1,1]/matriz_de_confusion[1].sum()\n",
        "\n",
        "print(\"-------------Resultados obtenidos por el clasificador 'todo no':----------------\")\n",
        "print('Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)')\n",
        "print(matriz_de_confusion)\n",
        "print()\n",
        "print('Accuracy: ', accuracy*100, '%')\n",
        "print('Sensitivity: ', sensitivity*100, '%')\n",
        "print('Specificity: ', specificity*100, '%')\n",
        "print('Puntuación: ', puntuar(sensitivity, specificity)*100, '%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jl8GyhcFczIb",
        "outputId": "0594c2f0-cccc-4188-8754-31e0930f21b1"
      },
      "execution_count": 170,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-------------Resultados obtenidos por nuestro clasificador:----------------\n",
            "Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)\n",
            "[[1350  494]\n",
            " [  66   55]]\n",
            "\n",
            "Accuracy:  71.50127226463104 %\n",
            "Sensitivity:  45.45454545454545 %\n",
            "Specificity:  73.21041214750542 %\n",
            "Puntuación:  59.33247880102543 %\n",
            "-------------Resultados obtenidos por el clasificador 'todo si':----------------\n",
            "Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)\n",
            "[[   0 1844]\n",
            " [   0  121]]\n",
            "\n",
            "Accuracy:  6.1577608142493645 %\n",
            "Sensitivity:  100.0 %\n",
            "Specificity:  0.0 %\n",
            "Puntuación:  50.0 %\n",
            "-------------Resultados obtenidos por el clasificador 'todo no':----------------\n",
            "Matriz de confusión : (Filas: 0/1 reales. Columnas: 0/1 predecidos)\n",
            "[[1844    0]\n",
            " [ 121    0]]\n",
            "\n",
            "Accuracy:  93.84223918575063 %\n",
            "Sensitivity:  0.0 %\n",
            "Specificity:  100.0 %\n",
            "Puntuación:  50.0 %\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Como era de esperar, todo 0 y todo 1 han obtenido respectivamente accuracys mejores y peores que la de nuestro clasificador, fruto de el desbalanceo de los datos. No obstante, lo que es claro, es que nuestro clasificador ha logrado mejor puntuación, es decir, ha logrado aumentar el promedio entre casos negativos acertados y casos positivos.\n",
        "\n",
        "Finalmente, Eout = 100 - 74.87% = 25.13%, lo cual sería el porcentaje de puntos mal clasificados. Algunos baselines consiguen menos, pero los resultados de nuestro modelo están mucho menos sesgados y puede predecir ciertas clases positivas (sensitivity).\n",
        "\n",
        "PD.: hay que tener en cuenta que este valor puede variar de unas ejecuciones a otras."
      ],
      "metadata": {
        "id": "7b-qKVASdicT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>8)  Construya las curvas de aprendizaje del modelo, y discuta la calidad del ajuste obtenido a la vista de la conducta de dichas curvas. 0.5 puntos. "
      ],
      "metadata": {
        "id": "3R044TTvg9Zf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "La curva se hará en base al accuracy, lo más correcto teóricamente."
      ],
      "metadata": {
        "id": "nnh1hUcgd4OX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = X_train.to_numpy()\n",
        "train_labels = y_train.to_numpy().flatten()\n",
        "indices = np.arange(train_data.shape[0])\n",
        "index_yes = np.array([indice for indice in indices if train_labels[indice] == 1])\n",
        "index_no = np.array([indice for indice in indices if train_labels[indice] == 0])\n",
        "np.random.shuffle(index_yes)\n",
        "np.random.shuffle(index_no)\n",
        "\n",
        "index_yes_train = index_yes[int(len(index_yes)*0.1):]\n",
        "index_yes_test = index_yes[:int(len(index_yes)*0.1)]\n",
        "index_no_train = index_no[int(len(index_no)*0.1):]\n",
        "index_no_test = index_no[:int(len(index_no)*0.1)]\n",
        "\n",
        "index_train = np.append( index_yes_train, index_no_train )\n",
        "index_test = np.append( index_yes_test, index_no_test )\n",
        "\n",
        "porcion_yes_train = index_yes_train.shape[0] / index_train.shape[0]\n",
        "porcion_no_train = index_no_train.shape[0] / index_train.shape[0]\n",
        "\n",
        "curva_validacion_data = train_data[index_test]\n",
        "curva_validacion_labels = train_labels[index_test]\n",
        "curva_data = train_data[index_train]\n",
        "curva_labels = train_labels[index_train]\n",
        "\n",
        "indices = np.arange(curva_data.shape[0])\n",
        "index_yes = np.array([indice for indice in indices if curva_labels[indice] == 1])\n",
        "index_no = np.array([indice for indice in indices if curva_labels[indice] == 0])\n",
        "\n",
        "eins = []\n",
        "eouts = []\n",
        "x = np.linspace(100, curva_data.shape[0],100)\n",
        "\n",
        "for num_datos in x:\n",
        "  num_it = int(curva_data.shape[0] / num_datos)\n",
        "  ein = 0\n",
        "  eout = 0\n",
        "  for i in range(num_it):\n",
        "    np.random.shuffle(index_yes)\n",
        "    np.random.shuffle(index_no)\n",
        "    index_yes_train = index_yes[:int(num_datos*porcion_yes_train)]\n",
        "    index_no_train = index_no[:int(num_datos*porcion_no_train)]\n",
        "\n",
        "    index_train = np.append( index_yes_train, index_no_train )\n",
        "    train_x = curva_data[index_train]\n",
        "    train_y = curva_labels[index_train]\n",
        "\n",
        "    w = Perceptron(max_iter=max_iter3, early_stopping=True, n_jobs=-1, penalty='l2', alpha=alpha, eta0=eta0, class_weight=None).fit(train_x,train_y)\n",
        "    ein += metrics.accuracy_score(train_y, w.predict(train_x))\n",
        "    eout += metrics.accuracy_score(curva_validacion_labels, w.predict(curva_validacion_data))\n",
        "\n",
        "  eins.append(ein/num_it)\n",
        "  eouts.append(eout/num_it)\n",
        "\n",
        "fig, ax = plt.subplots()\n",
        "\n",
        "ax.plot(x, eins, 'b-', label='Ein')\n",
        "ax.plot(x, eouts, 'r-', label='Eout')\n",
        "ax.set_title('Curvas de Aprendizaje')\n",
        "ax.set_xlabel('Número de datos')\n",
        "ax.set_ylabel('Error (Accuracy)');\n",
        "\n",
        "fig.legend()\n",
        "fig.show()"
      ],
      "metadata": {
        "id": "tch9k4mFg_KH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 500
        },
        "outputId": "1159427f-926b-4560-83ec-7f258bfb98d1"
      },
      "execution_count": 171,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Las curvas de aprendizaje que estamos observando parecen indicar la presencia de inconsistencia y aleatoriedad en el algoritmo del perceptrón. Es evidente que este algoritmo no garantiza un aumento en la calidad de los resultados a medida que se incrementa el número de datos. De hecho, como podemos ver en la gráfica, es posible afirmar que la calidad de nuestros resultados está influenciada en cierta medida por la aleatoriedad.\n",
        "\n",
        "Es importante destacar que el perceptrón es un algoritmo simple y lineal que no tiene en cuenta la complejidad de los datos o la presencia de relaciones no lineales. Por lo tanto, su rendimiento puede ser limitado en situaciones donde la naturaleza de los datos es más compleja.\n",
        "\n",
        "Es posible que para obtener resultados más consistentes y de mayor calidad, sea necesario utilizar algoritmos más avanzados que tengan en cuenta la complejidad y la variabilidad de los datos."
      ],
      "metadata": {
        "id": "rzzmUIFWeBOj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## <font color='blue'>9)  Suponga ahora que Ud. debe realizar este ajuste para una empresa que le ha proporcionado los datos, sin distinción entre training y test. ¿Cúal sería el mejor modelo que les propondría, y qué error  $E_{out}$ les diría que tiene? Justifique todas las decisiones. 0.5 puntos. "
      ],
      "metadata": {
        "id": "E_x9IPmEg_RX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Basándonos en el enfoque seguido en esta práctica, se ha realizado la selección del modelo considerado más apropiado. Para evaluar la capacidad de generalización de dicho modelo, se ha empleado la aproximación de Eout utilizando Etest, lo cual brinda una medida confiable. A pesar de que esta aproximación implica una reducción en el tamaño del conjunto de entrenamiento, no ha supuesto un problema debido a la abundancia de ejemplos disponibles.\n",
        "\n",
        "Asimismo, se han considerado otras alternativas para obtener Eout, como emplear el conjunto de datos de entrenamiento (Ein) o calcular un promedio de los errores de validación (Ecv). Sin embargo, estas opciones no se acercan tanto a la obtención de Eout a partir de un conjunto de prueba lo suficientemente amplio. Estas prácticas suelen emplearse cuando los datos son escasos o valiosos, y no es factible destinar una parte del conjunto de entrenamiento para pruebas. En nuestro caso, esto no ha sido necesario.\n",
        "\n",
        "Por otro lado, la validación cruzada nos permite probar y evaluar la calidad del modelo seleccionado, lo que resulta conveniente en la mayoría de los casos. Solo se puede obviar en situaciones en las que los tiempos de ejecución sean extremadamente largos, como horas o días, especialmente si los conjuntos de datos son lo suficientemente grandes como para obtener resultados confiables. A esto se le conoce como \"hold-out\".\n",
        "\n",
        "La elección de cómo realizar la validación generalmente se reduce a seleccionar el número de particiones a utilizar. En general, la validación cruzada de 5 particiones (5-CV) es comúnmente utilizada debido a su fiabilidad demostrada a lo largo del tiempo y la experiencia acumulada. No obstante, siempre depende del conjunto de datos en cuestión, por lo que es necesario tener en cuenta algunos aspectos:\n",
        "\n",
        "+ Menos particiones implican una menor seguridad obtenida y validaciones con conjuntos más pequeños. Por lo tanto, en conjuntos de datos relativamente grandes y costosos en términos de tiempo, a veces se opta por utilizar un 3-CV o incluso un 1-CV.\n",
        "\n",
        "+ Por otro lado, utilizar más particiones aumenta la seguridad de que la calidad del modelo sea real y no simplemente producto de la aleatoriedad. Sin embargo, también se incrementa el tiempo de ejecución debido al mayor número de validaciones requeridas. Este enfoque suele emplearse cuando los conjuntos de datos son pequeños o cuando no se va a utilizar un conjunto de prueba, por lo que el cálculo de Eout se basará en Ecv. En casos extremos, se puede utilizar la técnica de \"leave-one-out\", donde se realizan tantas particiones como datos disponibles, entrenando en cada iteración con casi todos los datos y validando con un solo dato. Esta técnica se utiliza cuando hay muy pocos datos y no se puede destinar una partición para el conjunto de prueba, y se requiere la máxima precisión posible.\n",
        "\n",
        "Dado que no tenemos restricciones de tiempo y disponemos de una cantidad generosa de ejemplos, no es necesario disminuir ni aumentar el número de particiones. La validación cruzada de 5 particiones será una elección adecuada en nuestro caso.\n",
        "\n",
        "Después de seguir el proceso en esta práctica, se ha obtenido una solución con un Eout de 25.13% en términos de Misclassification rate. Sin embargo, es importante mencionar que también se debe tener en cuenta la puntuación, sobre todo la sensitivity, que son los 1's bien clasificados.\n",
        "\n",
        "Dado que nuestro modelo usa una base de datos bastante desbalanceada, la clave sería ajustar el modelo de forma que se ajustara a las necesidades de la empresa. A lo mejor, es más catastrófico predecir los 1's mal que los 0's, o hay una cierta tregua en este aspecto."
      ],
      "metadata": {
        "id": "wmVxwmN0ihzJ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## REFLEXIONES FINALES"
      ],
      "metadata": {
        "id": "qkH8HPSFgdaC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "A modo de reflexión, se puede observar que el proceso de selección, ajuste y entrenamiento de un modelo no es en absoluto sencillo. Es un proceso complejo y extenso que, además, no garantiza resultados favorables.\n",
        "\n",
        "Existen numerosos aspectos a considerar y decisiones que tomar, lo cual hace prácticamente imposible elegir las mejores opciones. No es factible probar todas las opciones disponibles (por ejemplo, las infinitas transformaciones de datos posibles) y, aunque tengamos conocimientos, muchas decisiones no pueden basarse en evidencia empírica. Por lo tanto, debemos esforzarnos en obtener los mejores resultados posible, teniendo en cuenta el tiempo, las pruebas, el conocimiento, las heurísticas y, a veces, incluso la intuición.\n",
        "\n",
        "Si tuviera más tiempo, sería recomendable realizar más mejoras y pruebas, como:\n",
        "+ Tratar los valores atípicos (outliers).\n",
        "\n",
        "+ Experimentar con las transformaciones hechas (normalizar de otra manera, hacer one-hot a todas las categóricas, etc).\n",
        "\n",
        "+ Probar con diferentes parámetros o implementaciones para la regresión logística, especialmente variando los pesos de las clases.\n",
        "\n",
        "+ Intentar crear un conjunto de datos sin desequilibrio de clases y entrenar el modelo con ese conjunto.\n",
        "\n",
        "+ Por último, también se debería haber explorado la modificación del parámetro \"Average\" en SGDRegressor, ya que este valor se relaciona con el tamaño del mini-lote. Se recomienda encarecidamente probar diferentes valores de este parámetro en GridSearch o posteriormente.\n",
        "\n",
        "+ Subir el número máximo de iteraciones, ya que han saltado numerosos warnings con respecto a esto.\n",
        "\n",
        "En última instancia, este problema se caracteriza por su complejidad infinita y la ausencia de una única forma correcta de abordarlo."
      ],
      "metadata": {
        "id": "r27csU0AkClu"
      }
    }
  ]
}